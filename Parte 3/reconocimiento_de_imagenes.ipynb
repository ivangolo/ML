{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Imágenes en CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.  Carga de los datos. Generación de los sets de entrenamiento, validación y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        return X, np.array(Y)\n",
    "    \n",
    "def load_CIFAR10(PATH):\n",
    "    xs = []\n",
    "    ys = []    \n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "        \n",
    "    # training set\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    \n",
    "    # validation set \n",
    "    # valset_size = np.random.randint(5000, 9000)\n",
    "    valset_size = 7000\n",
    "    Xtr, Xval, Ytr, Yval = train_test_split(Xtr, Ytr, test_size=valset_size, random_state=42)    \n",
    "    \n",
    "    # Testing set \n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    \n",
    "    return Xtr, Ytr, Xval, Yval, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xval, Yval, Xte, Yte = load_CIFAR10('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scaler_function(X, scale=True):\n",
    "    scaler = StandardScaler(with_std=scale).fit(X)\n",
    "    return scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr_std = scaler_function(Xtr)\n",
    "Xte_std = scaler_function(Xte)\n",
    "Xval_std = scaler_function(Xval)\n",
    "\n",
    "Ytr_cat = to_categorical(Ytr)\n",
    "Yte_cat = to_categorical(Yte)\n",
    "Yval_cat = to_categorical(Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer modelo\n",
    "\n",
    "* Capa de entrada con función de activación relu, \n",
    "* Dropout 0.1\n",
    "* Una capa oculta de 100 nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43000 samples, validate on 7000 samples\n",
      "Epoch 1/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.9983 - acc: 0.2850 - val_loss: 1.8120 - val_acc: 0.3587\n",
      "Epoch 2/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.7536 - acc: 0.3852 - val_loss: 1.6937 - val_acc: 0.4054\n",
      "Epoch 3/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.6671 - acc: 0.4136 - val_loss: 1.6315 - val_acc: 0.4283\n",
      "Epoch 4/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.6135 - acc: 0.4323 - val_loss: 1.5938 - val_acc: 0.4423\n",
      "Epoch 5/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.5719 - acc: 0.4471 - val_loss: 1.5589 - val_acc: 0.4531\n",
      "Epoch 6/50\n",
      "43000/43000 [==============================] - 3s - loss: 1.5361 - acc: 0.4606 - val_loss: 1.5357 - val_acc: 0.4587\n",
      "Epoch 7/50\n",
      "43000/43000 [==============================] - 3s - loss: 1.5066 - acc: 0.4719 - val_loss: 1.5174 - val_acc: 0.4643\n",
      "Epoch 8/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.4818 - acc: 0.4813 - val_loss: 1.4970 - val_acc: 0.4766\n",
      "Epoch 9/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.4608 - acc: 0.4887 - val_loss: 1.4836 - val_acc: 0.4803\n",
      "Epoch 10/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.4375 - acc: 0.4990 - val_loss: 1.4722 - val_acc: 0.4831\n",
      "Epoch 11/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.4184 - acc: 0.5045 - val_loss: 1.4636 - val_acc: 0.4850\n",
      "Epoch 12/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.4004 - acc: 0.5103 - val_loss: 1.4575 - val_acc: 0.4860\n",
      "Epoch 13/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3844 - acc: 0.5166 - val_loss: 1.4504 - val_acc: 0.4923\n",
      "Epoch 14/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3728 - acc: 0.5201 - val_loss: 1.4443 - val_acc: 0.4924\n",
      "Epoch 15/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3574 - acc: 0.5285 - val_loss: 1.4356 - val_acc: 0.4956\n",
      "Epoch 16/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3397 - acc: 0.5343 - val_loss: 1.4314 - val_acc: 0.5014\n",
      "Epoch 17/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3340 - acc: 0.5334 - val_loss: 1.4267 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3147 - acc: 0.5387 - val_loss: 1.4177 - val_acc: 0.5077\n",
      "Epoch 19/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.3043 - acc: 0.5475 - val_loss: 1.4112 - val_acc: 0.5063\n",
      "Epoch 20/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2949 - acc: 0.5477 - val_loss: 1.4153 - val_acc: 0.5084\n",
      "Epoch 21/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2820 - acc: 0.5528 - val_loss: 1.4064 - val_acc: 0.5057\n",
      "Epoch 22/50\n",
      "43000/43000 [==============================] - 3s - loss: 1.2729 - acc: 0.5557 - val_loss: 1.4037 - val_acc: 0.5109\n",
      "Epoch 23/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2595 - acc: 0.5618 - val_loss: 1.4038 - val_acc: 0.5123\n",
      "Epoch 24/50\n",
      "43000/43000 [==============================] - 3s - loss: 1.2540 - acc: 0.5623 - val_loss: 1.3990 - val_acc: 0.5127\n",
      "Epoch 25/50\n",
      "43000/43000 [==============================] - 3s - loss: 1.2422 - acc: 0.5644 - val_loss: 1.3949 - val_acc: 0.5137\n",
      "Epoch 26/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2299 - acc: 0.5755 - val_loss: 1.3945 - val_acc: 0.5170\n",
      "Epoch 27/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2178 - acc: 0.5762 - val_loss: 1.3923 - val_acc: 0.5137\n",
      "Epoch 28/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2117 - acc: 0.5776 - val_loss: 1.3871 - val_acc: 0.5189\n",
      "Epoch 29/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.2031 - acc: 0.5799 - val_loss: 1.3898 - val_acc: 0.5187\n",
      "Epoch 30/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1906 - acc: 0.5881 - val_loss: 1.3909 - val_acc: 0.5214\n",
      "Epoch 31/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1855 - acc: 0.5873 - val_loss: 1.3843 - val_acc: 0.5186\n",
      "Epoch 32/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1791 - acc: 0.5906 - val_loss: 1.3880 - val_acc: 0.5180\n",
      "Epoch 33/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1681 - acc: 0.5953 - val_loss: 1.3907 - val_acc: 0.5161\n",
      "Epoch 34/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1586 - acc: 0.5983 - val_loss: 1.3865 - val_acc: 0.5187\n",
      "Epoch 35/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1553 - acc: 0.5983 - val_loss: 1.3835 - val_acc: 0.5229\n",
      "Epoch 36/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1476 - acc: 0.6036 - val_loss: 1.3829 - val_acc: 0.5207\n",
      "Epoch 37/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1379 - acc: 0.6057 - val_loss: 1.3850 - val_acc: 0.5259\n",
      "Epoch 38/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1233 - acc: 0.6102 - val_loss: 1.3897 - val_acc: 0.5227\n",
      "Epoch 39/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1198 - acc: 0.6133 - val_loss: 1.3864 - val_acc: 0.5213\n",
      "Epoch 40/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1128 - acc: 0.6151 - val_loss: 1.3848 - val_acc: 0.5216\n",
      "Epoch 41/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.1062 - acc: 0.6164 - val_loss: 1.3915 - val_acc: 0.5256\n",
      "Epoch 42/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.0975 - acc: 0.6161 - val_loss: 1.3900 - val_acc: 0.5221\n",
      "Epoch 43/50\n",
      "43000/43000 [==============================] - 2s - loss: 1.0927 - acc: 0.6184 - val_loss: 1.3940 - val_acc: 0.5234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc80b6d5050>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model0.add(Dropout(0.1))\n",
    "model0.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model0.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es0 = EarlyStopping(monitor='val_acc', patience=5, verbose=0, mode='auto', min_delta=0.001)\n",
    "model0.fit(Xtr_std, Ytr_cat, nb_epoch=50, batch_size=1000, verbose=1, callbacks=[es0], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/7000 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.523428571463\n"
     ]
    }
   ],
   "source": [
    "scores0 = model0.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43000 samples, validate on 7000 samples\n",
      "Epoch 1/200\n",
      "43000/43000 [==============================] - 3s - loss: 2.0017 - acc: 0.2840 - val_loss: 1.8017 - val_acc: 0.3587\n",
      "Epoch 2/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.7481 - acc: 0.3845 - val_loss: 1.6866 - val_acc: 0.3946\n",
      "Epoch 3/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.6685 - acc: 0.4142 - val_loss: 1.6288 - val_acc: 0.4191\n",
      "Epoch 4/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.6177 - acc: 0.4336 - val_loss: 1.5937 - val_acc: 0.4339\n",
      "Epoch 5/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.5787 - acc: 0.4467 - val_loss: 1.5630 - val_acc: 0.4453\n",
      "Epoch 6/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.5464 - acc: 0.4585 - val_loss: 1.5396 - val_acc: 0.4594\n",
      "Epoch 7/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.5163 - acc: 0.4670 - val_loss: 1.5178 - val_acc: 0.4620\n",
      "Epoch 8/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.4880 - acc: 0.4802 - val_loss: 1.5031 - val_acc: 0.4736\n",
      "Epoch 9/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.4666 - acc: 0.4872 - val_loss: 1.4885 - val_acc: 0.4780\n",
      "Epoch 10/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.4522 - acc: 0.4924 - val_loss: 1.4744 - val_acc: 0.4839\n",
      "Epoch 11/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.4293 - acc: 0.5000 - val_loss: 1.4639 - val_acc: 0.4847\n",
      "Epoch 12/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.4142 - acc: 0.5048 - val_loss: 1.4573 - val_acc: 0.4854\n",
      "Epoch 13/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3922 - acc: 0.5131 - val_loss: 1.4495 - val_acc: 0.4864\n",
      "Epoch 14/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.3800 - acc: 0.5191 - val_loss: 1.4373 - val_acc: 0.4921\n",
      "Epoch 15/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3601 - acc: 0.5252 - val_loss: 1.4294 - val_acc: 0.4937\n",
      "Epoch 16/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3482 - acc: 0.5276 - val_loss: 1.4270 - val_acc: 0.4983\n",
      "Epoch 17/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3352 - acc: 0.5320 - val_loss: 1.4214 - val_acc: 0.4967\n",
      "Epoch 18/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3214 - acc: 0.5376 - val_loss: 1.4142 - val_acc: 0.5004\n",
      "Epoch 19/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.3095 - acc: 0.5440 - val_loss: 1.4084 - val_acc: 0.5036\n",
      "Epoch 20/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2969 - acc: 0.5461 - val_loss: 1.4066 - val_acc: 0.5051\n",
      "Epoch 21/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2867 - acc: 0.5511 - val_loss: 1.4007 - val_acc: 0.5079\n",
      "Epoch 22/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2756 - acc: 0.5575 - val_loss: 1.3951 - val_acc: 0.5117\n",
      "Epoch 23/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2624 - acc: 0.5589 - val_loss: 1.3924 - val_acc: 0.5133\n",
      "Epoch 24/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2527 - acc: 0.5631 - val_loss: 1.3953 - val_acc: 0.5086\n",
      "Epoch 25/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2434 - acc: 0.5658 - val_loss: 1.3913 - val_acc: 0.5147\n",
      "Epoch 26/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2371 - acc: 0.5662 - val_loss: 1.3828 - val_acc: 0.5156\n",
      "Epoch 27/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2257 - acc: 0.5720 - val_loss: 1.3838 - val_acc: 0.5154\n",
      "Epoch 28/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2154 - acc: 0.5765 - val_loss: 1.3820 - val_acc: 0.5204\n",
      "Epoch 29/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.2023 - acc: 0.5806 - val_loss: 1.3791 - val_acc: 0.5146\n",
      "Epoch 30/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1951 - acc: 0.5846 - val_loss: 1.3789 - val_acc: 0.5187\n",
      "Epoch 31/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1876 - acc: 0.5867 - val_loss: 1.3754 - val_acc: 0.5224\n",
      "Epoch 32/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1775 - acc: 0.5890 - val_loss: 1.3755 - val_acc: 0.5193\n",
      "Epoch 33/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.1673 - acc: 0.5947 - val_loss: 1.3768 - val_acc: 0.5221\n",
      "Epoch 34/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.1595 - acc: 0.5936 - val_loss: 1.3832 - val_acc: 0.5206\n",
      "Epoch 35/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1519 - acc: 0.5994 - val_loss: 1.3742 - val_acc: 0.5209\n",
      "Epoch 36/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1450 - acc: 0.6015 - val_loss: 1.3700 - val_acc: 0.5196\n",
      "Epoch 37/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1385 - acc: 0.6023 - val_loss: 1.3737 - val_acc: 0.5197\n",
      "Epoch 38/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1258 - acc: 0.6070 - val_loss: 1.3700 - val_acc: 0.5209\n",
      "Epoch 39/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1215 - acc: 0.6083 - val_loss: 1.3753 - val_acc: 0.5243\n",
      "Epoch 40/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1120 - acc: 0.6107 - val_loss: 1.3725 - val_acc: 0.5234\n",
      "Epoch 41/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.1066 - acc: 0.6167 - val_loss: 1.3763 - val_acc: 0.5179\n",
      "Epoch 42/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0988 - acc: 0.6155 - val_loss: 1.3798 - val_acc: 0.5219\n",
      "Epoch 43/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0951 - acc: 0.6183 - val_loss: 1.3733 - val_acc: 0.5224\n",
      "Epoch 44/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0803 - acc: 0.6223 - val_loss: 1.3754 - val_acc: 0.5230\n",
      "Epoch 45/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0792 - acc: 0.6240 - val_loss: 1.3741 - val_acc: 0.5207\n",
      "Epoch 46/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0685 - acc: 0.6259 - val_loss: 1.3832 - val_acc: 0.5186\n",
      "Epoch 47/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0592 - acc: 0.6303 - val_loss: 1.3771 - val_acc: 0.5186\n",
      "Epoch 48/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0552 - acc: 0.6336 - val_loss: 1.3889 - val_acc: 0.5241\n",
      "Epoch 49/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0515 - acc: 0.6331 - val_loss: 1.3796 - val_acc: 0.5223\n",
      "Epoch 50/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0429 - acc: 0.6353 - val_loss: 1.3845 - val_acc: 0.5217\n",
      "Epoch 51/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0363 - acc: 0.6375 - val_loss: 1.3858 - val_acc: 0.5189\n",
      "Epoch 52/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0295 - acc: 0.6397 - val_loss: 1.3845 - val_acc: 0.5226\n",
      "Epoch 53/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0243 - acc: 0.6431 - val_loss: 1.3855 - val_acc: 0.5191\n",
      "Epoch 54/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0158 - acc: 0.6463 - val_loss: 1.3841 - val_acc: 0.5211\n",
      "Epoch 55/200\n",
      "43000/43000 [==============================] - 2s - loss: 1.0094 - acc: 0.6467 - val_loss: 1.3913 - val_acc: 0.5150\n",
      "Epoch 56/200\n",
      "43000/43000 [==============================] - 3s - loss: 1.0039 - acc: 0.6499 - val_loss: 1.3935 - val_acc: 0.5156\n",
      "Epoch 57/200\n",
      "43000/43000 [==============================] - 2s - loss: 0.9940 - acc: 0.6519 - val_loss: 1.3985 - val_acc: 0.5191\n",
      "Epoch 58/200\n",
      "43000/43000 [==============================] - 2s - loss: 0.9909 - acc: 0.6558 - val_loss: 1.3987 - val_acc: 0.5160\n",
      "Epoch 59/200\n",
      "43000/43000 [==============================] - 2s - loss: 0.9890 - acc: 0.6542 - val_loss: 1.4083 - val_acc: 0.5164\n",
      "Epoch 60/200\n",
      "43000/43000 [==============================] - 2s - loss: 0.9809 - acc: 0.6590 - val_loss: 1.3998 - val_acc: 0.5227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc80b24cd90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es1 = EarlyStopping(monitor='val_acc', patience=20, verbose=0, mode='auto', min_delta=0.001)\n",
    "model1.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es1], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/7000 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.522714285714\n"
     ]
    }
   ],
   "source": [
    "scores1 = model1.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43000 samples, validate on 7000 samples\n",
      "Epoch 1/100\n",
      "43000/43000 [==============================] - 20s - loss: 1.8754 - acc: 0.3476 - val_loss: 1.6351 - val_acc: 0.4276\n",
      "Epoch 2/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.5803 - acc: 0.4491 - val_loss: 1.5586 - val_acc: 0.4543\n",
      "Epoch 3/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.4898 - acc: 0.4839 - val_loss: 1.5099 - val_acc: 0.4706\n",
      "Epoch 4/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.4246 - acc: 0.5085 - val_loss: 1.4793 - val_acc: 0.4834\n",
      "Epoch 5/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.3758 - acc: 0.5257 - val_loss: 1.4574 - val_acc: 0.4889\n",
      "Epoch 6/100\n",
      "43000/43000 [==============================] - 20s - loss: 1.3305 - acc: 0.5432 - val_loss: 1.4394 - val_acc: 0.4961\n",
      "Epoch 7/100\n",
      "43000/43000 [==============================] - 20s - loss: 1.2900 - acc: 0.5560 - val_loss: 1.4302 - val_acc: 0.4989\n",
      "Epoch 8/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.2552 - acc: 0.5691 - val_loss: 1.4193 - val_acc: 0.5026\n",
      "Epoch 9/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.2217 - acc: 0.5813 - val_loss: 1.4064 - val_acc: 0.5097\n",
      "Epoch 10/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.1926 - acc: 0.5912 - val_loss: 1.3988 - val_acc: 0.5100\n",
      "Epoch 11/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.1624 - acc: 0.6030 - val_loss: 1.3975 - val_acc: 0.5144\n",
      "Epoch 12/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.1302 - acc: 0.6157 - val_loss: 1.3902 - val_acc: 0.5157\n",
      "Epoch 13/100\n",
      "43000/43000 [==============================] - 21s - loss: 1.1079 - acc: 0.6217 - val_loss: 1.3890 - val_acc: 0.5169\n",
      "Epoch 14/100\n",
      "43000/43000 [==============================] - 21s - loss: 1.0808 - acc: 0.6320 - val_loss: 1.3769 - val_acc: 0.5207\n",
      "Epoch 15/100\n",
      "43000/43000 [==============================] - 20s - loss: 1.0519 - acc: 0.6433 - val_loss: 1.3811 - val_acc: 0.5207\n",
      "Epoch 16/100\n",
      "43000/43000 [==============================] - 19s - loss: 1.0246 - acc: 0.6516 - val_loss: 1.3704 - val_acc: 0.5304\n",
      "Epoch 17/100\n",
      "43000/43000 [==============================] - 20s - loss: 1.0010 - acc: 0.6598 - val_loss: 1.3774 - val_acc: 0.5263\n",
      "Epoch 18/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.9755 - acc: 0.6699 - val_loss: 1.3790 - val_acc: 0.5237\n",
      "Epoch 19/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.9529 - acc: 0.6780 - val_loss: 1.3769 - val_acc: 0.5276\n",
      "Epoch 20/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.9286 - acc: 0.6857 - val_loss: 1.3757 - val_acc: 0.5284\n",
      "Epoch 21/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.9059 - acc: 0.6960 - val_loss: 1.3840 - val_acc: 0.5286\n",
      "Epoch 22/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.8835 - acc: 0.7044 - val_loss: 1.3708 - val_acc: 0.5351\n",
      "Epoch 23/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.8617 - acc: 0.7119 - val_loss: 1.3814 - val_acc: 0.5313\n",
      "Epoch 24/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.8409 - acc: 0.7183 - val_loss: 1.3868 - val_acc: 0.5353\n",
      "Epoch 25/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.8206 - acc: 0.7267 - val_loss: 1.3835 - val_acc: 0.5340\n",
      "Epoch 26/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.7985 - acc: 0.7343 - val_loss: 1.3971 - val_acc: 0.5334\n",
      "Epoch 27/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.7776 - acc: 0.7416 - val_loss: 1.3929 - val_acc: 0.5369\n",
      "Epoch 28/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.7657 - acc: 0.7443 - val_loss: 1.3932 - val_acc: 0.5360\n",
      "Epoch 29/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.7463 - acc: 0.7518 - val_loss: 1.3995 - val_acc: 0.5373\n",
      "Epoch 30/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.7198 - acc: 0.7616 - val_loss: 1.3991 - val_acc: 0.5381\n",
      "Epoch 31/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.7070 - acc: 0.7683 - val_loss: 1.4116 - val_acc: 0.5336\n",
      "Epoch 32/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.6878 - acc: 0.7751 - val_loss: 1.4210 - val_acc: 0.5340\n",
      "Epoch 33/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.6700 - acc: 0.7811 - val_loss: 1.4213 - val_acc: 0.5343\n",
      "Epoch 34/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.6526 - acc: 0.7880 - val_loss: 1.4283 - val_acc: 0.5339\n",
      "Epoch 35/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.6342 - acc: 0.7943 - val_loss: 1.4238 - val_acc: 0.5360\n",
      "Epoch 36/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.6212 - acc: 0.8000 - val_loss: 1.4344 - val_acc: 0.5391\n",
      "Epoch 37/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.6014 - acc: 0.8070 - val_loss: 1.4409 - val_acc: 0.5341\n",
      "Epoch 38/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5903 - acc: 0.8093 - val_loss: 1.4529 - val_acc: 0.5324\n",
      "Epoch 39/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5749 - acc: 0.8156 - val_loss: 1.4496 - val_acc: 0.5389\n",
      "Epoch 40/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5608 - acc: 0.8203 - val_loss: 1.4608 - val_acc: 0.5351\n",
      "Epoch 41/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5451 - acc: 0.8280 - val_loss: 1.4718 - val_acc: 0.5363\n",
      "Epoch 42/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5295 - acc: 0.8332 - val_loss: 1.4604 - val_acc: 0.5403\n",
      "Epoch 43/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5155 - acc: 0.8383 - val_loss: 1.4785 - val_acc: 0.5360\n",
      "Epoch 44/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.5043 - acc: 0.8414 - val_loss: 1.4954 - val_acc: 0.5369\n",
      "Epoch 45/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4917 - acc: 0.8461 - val_loss: 1.4907 - val_acc: 0.5431\n",
      "Epoch 46/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4794 - acc: 0.8494 - val_loss: 1.4940 - val_acc: 0.5347\n",
      "Epoch 47/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4694 - acc: 0.8537 - val_loss: 1.5110 - val_acc: 0.5383\n",
      "Epoch 48/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4562 - acc: 0.8573 - val_loss: 1.5129 - val_acc: 0.5363\n",
      "Epoch 49/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.4427 - acc: 0.8612 - val_loss: 1.5203 - val_acc: 0.5387\n",
      "Epoch 50/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4359 - acc: 0.8654 - val_loss: 1.5297 - val_acc: 0.5394\n",
      "Epoch 51/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4217 - acc: 0.8707 - val_loss: 1.5269 - val_acc: 0.5419\n",
      "Epoch 52/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.4091 - acc: 0.8743 - val_loss: 1.5487 - val_acc: 0.5357\n",
      "Epoch 53/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.3979 - acc: 0.8798 - val_loss: 1.5469 - val_acc: 0.5414\n",
      "Epoch 54/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.3926 - acc: 0.8797 - val_loss: 1.5621 - val_acc: 0.5364\n",
      "Epoch 55/100\n",
      "43000/43000 [==============================] - 20s - loss: 0.3837 - acc: 0.8843 - val_loss: 1.5694 - val_acc: 0.5363\n",
      "Epoch 56/100\n",
      "43000/43000 [==============================] - 19s - loss: 0.3737 - acc: 0.8881 - val_loss: 1.5788 - val_acc: 0.5370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc80ade6d10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(1024, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es2 = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto', min_delta=0.001)\n",
    "model2.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es2], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 3s     \n",
      "\n",
      "Accuracy on validation set: 0.537000000034\n"
     ]
    }
   ],
   "source": [
    "scores2 = model2.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 3s - loss: 2.2341 - acc: 0.1871 - val_loss: 2.1014 - val_acc: 0.2624\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.9865 - acc: 0.2934 - val_loss: 1.8864 - val_acc: 0.3292\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.8437 - acc: 0.3444 - val_loss: 1.7812 - val_acc: 0.3665\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.7661 - acc: 0.3707 - val_loss: 1.7171 - val_acc: 0.3901\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.7082 - acc: 0.3937 - val_loss: 1.6698 - val_acc: 0.4047\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.6673 - acc: 0.4081 - val_loss: 1.6307 - val_acc: 0.4208\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.6304 - acc: 0.4233 - val_loss: 1.5989 - val_acc: 0.4289\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5955 - acc: 0.4346 - val_loss: 1.5715 - val_acc: 0.4404\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5684 - acc: 0.4455 - val_loss: 1.5487 - val_acc: 0.4440\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5384 - acc: 0.4556 - val_loss: 1.5270 - val_acc: 0.4544\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5158 - acc: 0.4645 - val_loss: 1.5070 - val_acc: 0.4652\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4911 - acc: 0.4732 - val_loss: 1.4916 - val_acc: 0.4723\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4733 - acc: 0.4794 - val_loss: 1.4774 - val_acc: 0.4752\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4509 - acc: 0.4867 - val_loss: 1.4658 - val_acc: 0.4760\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4380 - acc: 0.4901 - val_loss: 1.4498 - val_acc: 0.4819\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4151 - acc: 0.5008 - val_loss: 1.4396 - val_acc: 0.4836\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3999 - acc: 0.5069 - val_loss: 1.4318 - val_acc: 0.4849\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3901 - acc: 0.5097 - val_loss: 1.4209 - val_acc: 0.4911\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3693 - acc: 0.5150 - val_loss: 1.4172 - val_acc: 0.4929\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3555 - acc: 0.5217 - val_loss: 1.4099 - val_acc: 0.4965\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3446 - acc: 0.5241 - val_loss: 1.4020 - val_acc: 0.4995\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3310 - acc: 0.5261 - val_loss: 1.3968 - val_acc: 0.4976\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3183 - acc: 0.5355 - val_loss: 1.3874 - val_acc: 0.5044\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3067 - acc: 0.5360 - val_loss: 1.3865 - val_acc: 0.5049\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2933 - acc: 0.5420 - val_loss: 1.3803 - val_acc: 0.5076\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2873 - acc: 0.5469 - val_loss: 1.3742 - val_acc: 0.5063\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2712 - acc: 0.5525 - val_loss: 1.3699 - val_acc: 0.5140\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2620 - acc: 0.5550 - val_loss: 1.3636 - val_acc: 0.5127\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2510 - acc: 0.5568 - val_loss: 1.3618 - val_acc: 0.5140\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2407 - acc: 0.5618 - val_loss: 1.3602 - val_acc: 0.5124\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2330 - acc: 0.5667 - val_loss: 1.3631 - val_acc: 0.5165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89517acfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(100, init='uniform', activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es3 = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "model3.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es3], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.516533333349\n"
     ]
    }
   ],
   "source": [
    "scores3 = model3.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.3007 - acc: 0.1313 - val_loss: 2.2973 - val_acc: 0.1779\n",
      "Epoch 2/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.2892 - acc: 0.1876 - val_loss: 2.2725 - val_acc: 0.1868\n",
      "Epoch 3/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.2173 - acc: 0.1929 - val_loss: 2.1325 - val_acc: 0.2205\n",
      "Epoch 4/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.0596 - acc: 0.2397 - val_loss: 1.9913 - val_acc: 0.2593\n",
      "Epoch 5/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.9599 - acc: 0.2768 - val_loss: 1.9103 - val_acc: 0.2907\n",
      "Epoch 6/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.8956 - acc: 0.3004 - val_loss: 1.8485 - val_acc: 0.3196\n",
      "Epoch 7/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.8434 - acc: 0.3215 - val_loss: 1.7937 - val_acc: 0.3409\n",
      "Epoch 8/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7972 - acc: 0.3398 - val_loss: 1.7569 - val_acc: 0.3579\n",
      "Epoch 9/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7617 - acc: 0.3591 - val_loss: 1.7216 - val_acc: 0.3697\n",
      "Epoch 10/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7241 - acc: 0.3763 - val_loss: 1.6841 - val_acc: 0.3852\n",
      "Epoch 11/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6848 - acc: 0.3912 - val_loss: 1.6440 - val_acc: 0.4053\n",
      "Epoch 12/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6478 - acc: 0.4046 - val_loss: 1.6109 - val_acc: 0.4188\n",
      "Epoch 13/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6180 - acc: 0.4187 - val_loss: 1.5885 - val_acc: 0.4256\n",
      "Epoch 14/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5935 - acc: 0.4282 - val_loss: 1.5705 - val_acc: 0.4352\n",
      "Epoch 15/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5671 - acc: 0.4368 - val_loss: 1.5525 - val_acc: 0.4376\n",
      "Epoch 16/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5458 - acc: 0.4456 - val_loss: 1.5336 - val_acc: 0.4488\n",
      "Epoch 17/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5225 - acc: 0.4543 - val_loss: 1.5184 - val_acc: 0.4545\n",
      "Epoch 18/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5074 - acc: 0.4590 - val_loss: 1.5053 - val_acc: 0.4600\n",
      "Epoch 19/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4867 - acc: 0.4681 - val_loss: 1.4916 - val_acc: 0.4671\n",
      "Epoch 20/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4715 - acc: 0.4742 - val_loss: 1.4766 - val_acc: 0.4747\n",
      "Epoch 21/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4506 - acc: 0.4812 - val_loss: 1.4671 - val_acc: 0.4795\n",
      "Epoch 22/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4404 - acc: 0.4843 - val_loss: 1.4596 - val_acc: 0.4815\n",
      "Epoch 23/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4168 - acc: 0.4930 - val_loss: 1.4420 - val_acc: 0.4896\n",
      "Epoch 24/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4064 - acc: 0.4980 - val_loss: 1.4380 - val_acc: 0.4893\n",
      "Epoch 25/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3893 - acc: 0.5030 - val_loss: 1.4366 - val_acc: 0.4908\n",
      "Epoch 26/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3773 - acc: 0.5042 - val_loss: 1.4257 - val_acc: 0.4957\n",
      "Epoch 27/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3639 - acc: 0.5132 - val_loss: 1.4168 - val_acc: 0.4989\n",
      "Epoch 28/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3502 - acc: 0.5176 - val_loss: 1.4096 - val_acc: 0.5040\n",
      "Epoch 29/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3369 - acc: 0.5224 - val_loss: 1.4042 - val_acc: 0.5027\n",
      "Epoch 30/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3221 - acc: 0.5301 - val_loss: 1.4068 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3106 - acc: 0.5306 - val_loss: 1.3939 - val_acc: 0.5055\n",
      "Epoch 32/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3017 - acc: 0.5352 - val_loss: 1.3943 - val_acc: 0.5064\n",
      "Epoch 33/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2909 - acc: 0.5389 - val_loss: 1.3903 - val_acc: 0.5105\n",
      "Epoch 34/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2746 - acc: 0.5445 - val_loss: 1.3846 - val_acc: 0.5123\n",
      "Epoch 35/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2656 - acc: 0.5485 - val_loss: 1.3808 - val_acc: 0.5084\n",
      "Epoch 36/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2575 - acc: 0.5518 - val_loss: 1.3782 - val_acc: 0.5180\n",
      "Epoch 37/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2477 - acc: 0.5555 - val_loss: 1.3769 - val_acc: 0.5143\n",
      "Epoch 38/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2387 - acc: 0.5569 - val_loss: 1.3766 - val_acc: 0.5147\n",
      "Epoch 39/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2282 - acc: 0.5606 - val_loss: 1.3736 - val_acc: 0.5179\n",
      "Epoch 40/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2139 - acc: 0.5669 - val_loss: 1.3668 - val_acc: 0.5167\n",
      "Epoch 41/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2051 - acc: 0.5680 - val_loss: 1.3695 - val_acc: 0.5188\n",
      "Epoch 42/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1991 - acc: 0.5705 - val_loss: 1.3639 - val_acc: 0.5195\n",
      "Epoch 43/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1895 - acc: 0.5755 - val_loss: 1.3776 - val_acc: 0.5200\n",
      "Epoch 44/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1756 - acc: 0.5798 - val_loss: 1.3755 - val_acc: 0.5160\n",
      "Epoch 45/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1731 - acc: 0.5808 - val_loss: 1.3702 - val_acc: 0.5201\n",
      "Epoch 46/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1588 - acc: 0.5888 - val_loss: 1.3687 - val_acc: 0.5261\n",
      "Epoch 47/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1498 - acc: 0.5877 - val_loss: 1.3635 - val_acc: 0.5260\n",
      "Epoch 48/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1472 - acc: 0.5889 - val_loss: 1.3589 - val_acc: 0.5241\n",
      "Epoch 49/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1363 - acc: 0.5920 - val_loss: 1.3639 - val_acc: 0.5228\n",
      "Epoch 50/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1295 - acc: 0.5977 - val_loss: 1.3762 - val_acc: 0.5187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8950ac2990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(100, init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(100, init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es4 = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "model4.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es4], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7456/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.497199999968\n"
     ]
    }
   ],
   "source": [
    "scores4 = model4.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.0959 - acc: 0.2365 - val_loss: 1.8748 - val_acc: 0.3336\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.8508 - acc: 0.3424 - val_loss: 1.7429 - val_acc: 0.3852\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.7512 - acc: 0.3771 - val_loss: 1.6691 - val_acc: 0.4099\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6903 - acc: 0.4026 - val_loss: 1.6207 - val_acc: 0.4295\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6464 - acc: 0.4182 - val_loss: 1.5849 - val_acc: 0.4381\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6061 - acc: 0.4316 - val_loss: 1.5573 - val_acc: 0.4448\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.5802 - acc: 0.4408 - val_loss: 1.5322 - val_acc: 0.4641\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5448 - acc: 0.4543 - val_loss: 1.5087 - val_acc: 0.4673\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5210 - acc: 0.4635 - val_loss: 1.4914 - val_acc: 0.4697\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4999 - acc: 0.4719 - val_loss: 1.4746 - val_acc: 0.4839\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4725 - acc: 0.4786 - val_loss: 1.4607 - val_acc: 0.4891\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4552 - acc: 0.4863 - val_loss: 1.4440 - val_acc: 0.4944\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4331 - acc: 0.4950 - val_loss: 1.4302 - val_acc: 0.4983\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4116 - acc: 0.5009 - val_loss: 1.4205 - val_acc: 0.5037\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3946 - acc: 0.5087 - val_loss: 1.4072 - val_acc: 0.5067\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.3790 - acc: 0.5139 - val_loss: 1.4003 - val_acc: 0.5109\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3605 - acc: 0.5195 - val_loss: 1.3904 - val_acc: 0.5139\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3472 - acc: 0.5258 - val_loss: 1.3851 - val_acc: 0.5112\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3284 - acc: 0.5319 - val_loss: 1.3786 - val_acc: 0.5148\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3132 - acc: 0.5391 - val_loss: 1.3708 - val_acc: 0.5159\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3001 - acc: 0.5434 - val_loss: 1.3633 - val_acc: 0.5249\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2854 - acc: 0.5485 - val_loss: 1.3572 - val_acc: 0.5223\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2675 - acc: 0.5520 - val_loss: 1.3481 - val_acc: 0.5241\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2551 - acc: 0.5560 - val_loss: 1.3439 - val_acc: 0.5271\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2423 - acc: 0.5630 - val_loss: 1.3395 - val_acc: 0.5285\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2302 - acc: 0.5642 - val_loss: 1.3358 - val_acc: 0.5295\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2114 - acc: 0.5716 - val_loss: 1.3268 - val_acc: 0.5327\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2035 - acc: 0.5745 - val_loss: 1.3215 - val_acc: 0.5329\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1917 - acc: 0.5783 - val_loss: 1.3155 - val_acc: 0.5352\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1773 - acc: 0.5843 - val_loss: 1.3145 - val_acc: 0.5372\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1668 - acc: 0.5890 - val_loss: 1.3070 - val_acc: 0.5396\n",
      "Epoch 32/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1537 - acc: 0.5951 - val_loss: 1.3090 - val_acc: 0.5393\n",
      "Epoch 33/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1353 - acc: 0.5981 - val_loss: 1.2999 - val_acc: 0.5460\n",
      "Epoch 34/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1339 - acc: 0.5989 - val_loss: 1.3053 - val_acc: 0.5416\n",
      "Epoch 35/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1148 - acc: 0.6056 - val_loss: 1.3003 - val_acc: 0.5449\n",
      "Epoch 36/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1069 - acc: 0.6087 - val_loss: 1.2995 - val_acc: 0.5412\n",
      "Epoch 37/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0965 - acc: 0.6129 - val_loss: 1.2951 - val_acc: 0.5484\n",
      "Epoch 38/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0808 - acc: 0.6169 - val_loss: 1.2943 - val_acc: 0.5492\n",
      "Epoch 39/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0706 - acc: 0.6209 - val_loss: 1.2925 - val_acc: 0.5503\n",
      "Epoch 40/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0543 - acc: 0.6252 - val_loss: 1.2870 - val_acc: 0.5512\n",
      "Epoch 41/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0484 - acc: 0.6300 - val_loss: 1.2888 - val_acc: 0.5521\n",
      "Epoch 42/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0417 - acc: 0.6311 - val_loss: 1.2893 - val_acc: 0.5503\n",
      "Epoch 43/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0257 - acc: 0.6377 - val_loss: 1.2842 - val_acc: 0.5524\n",
      "Epoch 44/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0147 - acc: 0.6417 - val_loss: 1.2859 - val_acc: 0.5533\n",
      "Epoch 45/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0044 - acc: 0.6428 - val_loss: 1.2842 - val_acc: 0.5561\n",
      "Epoch 46/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9950 - acc: 0.6490 - val_loss: 1.2866 - val_acc: 0.5524\n",
      "Epoch 47/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9856 - acc: 0.6525 - val_loss: 1.2839 - val_acc: 0.5587\n",
      "Epoch 48/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9762 - acc: 0.6544 - val_loss: 1.2870 - val_acc: 0.5548\n",
      "Epoch 49/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9607 - acc: 0.6595 - val_loss: 1.2826 - val_acc: 0.5573\n",
      "Epoch 50/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9572 - acc: 0.6601 - val_loss: 1.2863 - val_acc: 0.5580\n",
      "Epoch 51/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9424 - acc: 0.6653 - val_loss: 1.2822 - val_acc: 0.5587\n",
      "Epoch 52/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9329 - acc: 0.6672 - val_loss: 1.2856 - val_acc: 0.5549\n",
      "Epoch 53/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9273 - acc: 0.6729 - val_loss: 1.2908 - val_acc: 0.5609\n",
      "Epoch 54/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9197 - acc: 0.6728 - val_loss: 1.2842 - val_acc: 0.5592\n",
      "Epoch 55/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9060 - acc: 0.6770 - val_loss: 1.2773 - val_acc: 0.5603\n",
      "Epoch 56/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8910 - acc: 0.6806 - val_loss: 1.2928 - val_acc: 0.5568\n",
      "Epoch 57/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8859 - acc: 0.6846 - val_loss: 1.2938 - val_acc: 0.5599\n",
      "Epoch 58/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.8736 - acc: 0.6910 - val_loss: 1.2867 - val_acc: 0.5592\n",
      "Epoch 59/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8684 - acc: 0.6909 - val_loss: 1.2915 - val_acc: 0.5620\n",
      "Epoch 60/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8570 - acc: 0.6964 - val_loss: 1.2916 - val_acc: 0.5617\n",
      "Epoch 61/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8514 - acc: 0.6984 - val_loss: 1.2981 - val_acc: 0.5591\n",
      "Epoch 62/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8343 - acc: 0.7053 - val_loss: 1.2992 - val_acc: 0.5617\n",
      "Epoch 63/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8326 - acc: 0.7028 - val_loss: 1.3087 - val_acc: 0.5591\n",
      "Epoch 64/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8234 - acc: 0.7080 - val_loss: 1.3084 - val_acc: 0.5613\n",
      "Epoch 65/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8150 - acc: 0.7095 - val_loss: 1.3096 - val_acc: 0.5580\n",
      "Epoch 66/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8034 - acc: 0.7129 - val_loss: 1.3159 - val_acc: 0.5619\n",
      "Epoch 67/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8015 - acc: 0.7134 - val_loss: 1.3002 - val_acc: 0.5645\n",
      "Epoch 68/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7871 - acc: 0.7191 - val_loss: 1.3110 - val_acc: 0.5552\n",
      "Epoch 69/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7773 - acc: 0.7226 - val_loss: 1.3206 - val_acc: 0.5640\n",
      "Epoch 70/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7729 - acc: 0.7251 - val_loss: 1.3270 - val_acc: 0.5564\n",
      "Epoch 71/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7686 - acc: 0.7261 - val_loss: 1.3184 - val_acc: 0.5592\n",
      "Epoch 72/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7591 - acc: 0.7286 - val_loss: 1.3176 - val_acc: 0.5612\n",
      "Epoch 73/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7505 - acc: 0.7316 - val_loss: 1.3318 - val_acc: 0.5579\n",
      "Epoch 74/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7364 - acc: 0.7351 - val_loss: 1.3379 - val_acc: 0.5617\n",
      "Epoch 75/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7351 - acc: 0.7387 - val_loss: 1.3271 - val_acc: 0.5647\n",
      "Epoch 76/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7258 - acc: 0.7402 - val_loss: 1.3404 - val_acc: 0.5583\n",
      "Epoch 77/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7225 - acc: 0.7417 - val_loss: 1.3489 - val_acc: 0.5629\n",
      "Epoch 78/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7128 - acc: 0.7464 - val_loss: 1.3386 - val_acc: 0.5632\n",
      "Epoch 79/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7020 - acc: 0.7500 - val_loss: 1.3472 - val_acc: 0.5600\n",
      "Epoch 80/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6978 - acc: 0.7515 - val_loss: 1.3486 - val_acc: 0.5608\n",
      "Epoch 81/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6911 - acc: 0.7549 - val_loss: 1.3592 - val_acc: 0.5608\n",
      "Epoch 82/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6867 - acc: 0.7559 - val_loss: 1.3449 - val_acc: 0.5648\n",
      "Epoch 83/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6730 - acc: 0.7596 - val_loss: 1.3698 - val_acc: 0.5632\n",
      "Epoch 84/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6606 - acc: 0.7630 - val_loss: 1.3716 - val_acc: 0.5563\n",
      "Epoch 85/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.6584 - acc: 0.7664 - val_loss: 1.3655 - val_acc: 0.5645\n",
      "Epoch 86/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6580 - acc: 0.7675 - val_loss: 1.3660 - val_acc: 0.5581\n",
      "Epoch 87/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6433 - acc: 0.7697 - val_loss: 1.3714 - val_acc: 0.5632\n",
      "Epoch 88/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6381 - acc: 0.7736 - val_loss: 1.3889 - val_acc: 0.5613\n",
      "Epoch 89/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6369 - acc: 0.7732 - val_loss: 1.3897 - val_acc: 0.5567\n",
      "Epoch 90/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6312 - acc: 0.7756 - val_loss: 1.3972 - val_acc: 0.5592\n",
      "Epoch 91/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6213 - acc: 0.7776 - val_loss: 1.3987 - val_acc: 0.5533\n",
      "Epoch 92/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6167 - acc: 0.7817 - val_loss: 1.3894 - val_acc: 0.5567\n",
      "Epoch 93/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6044 - acc: 0.7816 - val_loss: 1.4043 - val_acc: 0.5601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89481cb210>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(512, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, init='uniform', activation='relu'))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model5.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es5 = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto')\n",
    "model5.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, callbacks=[es5], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s     \n",
      "\n",
      "Accuracy on validation set: 0.560133333333\n"
     ]
    }
   ],
   "source": [
    "scores5 = model5.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores5[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.2635 - acc: 0.1674 - val_loss: 2.1625 - val_acc: 0.2507\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.0543 - acc: 0.2545 - val_loss: 1.9176 - val_acc: 0.3077\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.9012 - acc: 0.3103 - val_loss: 1.8112 - val_acc: 0.3493\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.8187 - acc: 0.3455 - val_loss: 1.7394 - val_acc: 0.3763\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.7565 - acc: 0.3685 - val_loss: 1.6831 - val_acc: 0.3908\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.7084 - acc: 0.3890 - val_loss: 1.6437 - val_acc: 0.4061\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.6619 - acc: 0.4088 - val_loss: 1.6096 - val_acc: 0.4221\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.6266 - acc: 0.4233 - val_loss: 1.5815 - val_acc: 0.4309\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.5961 - acc: 0.4315 - val_loss: 1.5517 - val_acc: 0.4424\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5651 - acc: 0.4464 - val_loss: 1.5313 - val_acc: 0.4503\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5358 - acc: 0.4530 - val_loss: 1.5092 - val_acc: 0.4616\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5107 - acc: 0.4660 - val_loss: 1.4931 - val_acc: 0.4679\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4857 - acc: 0.4739 - val_loss: 1.4723 - val_acc: 0.4767\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4603 - acc: 0.4864 - val_loss: 1.4576 - val_acc: 0.4835\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4365 - acc: 0.4919 - val_loss: 1.4395 - val_acc: 0.4919\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4115 - acc: 0.5007 - val_loss: 1.4275 - val_acc: 0.4936\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3904 - acc: 0.5100 - val_loss: 1.4189 - val_acc: 0.5005\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3669 - acc: 0.5168 - val_loss: 1.4071 - val_acc: 0.4997\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3479 - acc: 0.5243 - val_loss: 1.4018 - val_acc: 0.5012\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3285 - acc: 0.5318 - val_loss: 1.3849 - val_acc: 0.5092\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3056 - acc: 0.5398 - val_loss: 1.3834 - val_acc: 0.5119\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2868 - acc: 0.5435 - val_loss: 1.3665 - val_acc: 0.5144\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2667 - acc: 0.5532 - val_loss: 1.3600 - val_acc: 0.5196\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2530 - acc: 0.5542 - val_loss: 1.3580 - val_acc: 0.5168\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2273 - acc: 0.5657 - val_loss: 1.3510 - val_acc: 0.5211\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2114 - acc: 0.5698 - val_loss: 1.3391 - val_acc: 0.5269\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.1922 - acc: 0.5786 - val_loss: 1.3407 - val_acc: 0.5304\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.1734 - acc: 0.5854 - val_loss: 1.3341 - val_acc: 0.5311\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1583 - acc: 0.5890 - val_loss: 1.3292 - val_acc: 0.5307\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1374 - acc: 0.5944 - val_loss: 1.3290 - val_acc: 0.5341\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1175 - acc: 0.6030 - val_loss: 1.3314 - val_acc: 0.5303\n",
      "Epoch 32/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1028 - acc: 0.6085 - val_loss: 1.3221 - val_acc: 0.5387\n",
      "Epoch 33/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0844 - acc: 0.6165 - val_loss: 1.3266 - val_acc: 0.5375\n",
      "Epoch 34/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0755 - acc: 0.6199 - val_loss: 1.3245 - val_acc: 0.5360\n",
      "Epoch 35/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.0525 - acc: 0.6263 - val_loss: 1.3222 - val_acc: 0.5413\n",
      "Epoch 36/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.0426 - acc: 0.6293 - val_loss: 1.3228 - val_acc: 0.5428\n",
      "Epoch 37/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0170 - acc: 0.6395 - val_loss: 1.3337 - val_acc: 0.5340\n",
      "Epoch 38/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0004 - acc: 0.6464 - val_loss: 1.3327 - val_acc: 0.5400\n",
      "Epoch 39/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9891 - acc: 0.6476 - val_loss: 1.3265 - val_acc: 0.5419\n",
      "Epoch 40/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9701 - acc: 0.6544 - val_loss: 1.3448 - val_acc: 0.5437\n",
      "Epoch 41/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9540 - acc: 0.6595 - val_loss: 1.3278 - val_acc: 0.5484\n",
      "Epoch 42/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9377 - acc: 0.6664 - val_loss: 1.3411 - val_acc: 0.5449\n",
      "Epoch 43/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9232 - acc: 0.6696 - val_loss: 1.3420 - val_acc: 0.5471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f894aa30c90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(512, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.1))\n",
    "model6.add(Dense(128, init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.6))\n",
    "model6.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model6.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es6 = EarlyStopping(monitor='val_accu', patience=10, verbose=0, mode='auto')\n",
    "model6.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es6], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s     \n",
      "\n",
      "Accuracy on validation set: 0.547066666635\n"
     ]
    }
   ],
   "source": [
    "scores6 = model6.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores6[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from top_level_features import hog_features\n",
    "from top_level_features import color_histogram_hsv\n",
    "from top_level_features import extract_features\n",
    "\n",
    "Xtr, Ytr, Xval, Yval, Xte, Yte = load_CIFAR10('data')\n",
    "features = extract_features(Xtr,[hog_features]) #extrae hog features\n",
    "features = extract_features(Xtr,[color_histogram_hsv]) #extrae histogramas de color\n",
    "features = extract_features(Xtr,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "\n",
    "print Xtr.shape\n",
    "print features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
