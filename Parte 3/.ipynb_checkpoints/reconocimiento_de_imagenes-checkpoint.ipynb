{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Imágenes en CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.  Carga de los datos. Generación de los sets de entrenamiento, validación y pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        return X, np.array(Y)\n",
    "    \n",
    "def load_CIFAR10(PATH):\n",
    "    xs = []\n",
    "    ys = []    \n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "        \n",
    "    # training set\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    \n",
    "    # validation set \n",
    "    # valset_size = np.random.randint(5000, 9000)\n",
    "    valset_size = 7500\n",
    "    Xtr, Xval, Ytr, Yval = train_test_split(Xtr, Ytr, test_size=valset_size/float(Xtr.shape[0]), random_state=42)    \n",
    "    \n",
    "    # Testing set \n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    \n",
    "    return Xtr, Ytr, Xval, Yval, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xval, Yval, Xte, Yte = load_CIFAR10('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scaler_function(X, scale=True):\n",
    "    scaler = StandardScaler(with_std=scale).fit(X)\n",
    "    return scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr_std = scaler_function(Xtr)\n",
    "Xte_std = scaler_function(Xte)\n",
    "Xval_std = scaler_function(Xval)\n",
    "\n",
    "Ytr_cat = to_categorical(Ytr)\n",
    "Yte_cat = to_categorical(Yte)\n",
    "Yval_cat = to_categorical(Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer modelo\n",
    "\n",
    "* Capa de entrada con función de activación relu, \n",
    "* Dropout 0.1\n",
    "* Una capa oculta de 100 nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.0053 - acc: 0.2778 - val_loss: 1.8071 - val_acc: 0.3613\n",
      "Epoch 2/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.7550 - acc: 0.3808 - val_loss: 1.6911 - val_acc: 0.4031\n",
      "Epoch 3/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.6728 - acc: 0.4101 - val_loss: 1.6291 - val_acc: 0.4252\n",
      "Epoch 4/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.6173 - acc: 0.4294 - val_loss: 1.5901 - val_acc: 0.4436\n",
      "Epoch 5/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.5790 - acc: 0.4445 - val_loss: 1.5637 - val_acc: 0.4551\n",
      "Epoch 6/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.5476 - acc: 0.4576 - val_loss: 1.5367 - val_acc: 0.4627\n",
      "Epoch 7/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.5194 - acc: 0.4657 - val_loss: 1.5191 - val_acc: 0.4671\n",
      "Epoch 8/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.4931 - acc: 0.4738 - val_loss: 1.5025 - val_acc: 0.4768\n",
      "Epoch 9/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.4719 - acc: 0.4835 - val_loss: 1.4879 - val_acc: 0.4840\n",
      "Epoch 10/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.4492 - acc: 0.4940 - val_loss: 1.4744 - val_acc: 0.4852\n",
      "Epoch 11/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.4309 - acc: 0.4990 - val_loss: 1.4647 - val_acc: 0.4855\n",
      "Epoch 12/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.4130 - acc: 0.5062 - val_loss: 1.4524 - val_acc: 0.4908\n",
      "Epoch 13/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3970 - acc: 0.5120 - val_loss: 1.4448 - val_acc: 0.4939\n",
      "Epoch 14/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3793 - acc: 0.5160 - val_loss: 1.4393 - val_acc: 0.4921\n",
      "Epoch 15/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3642 - acc: 0.5238 - val_loss: 1.4329 - val_acc: 0.4975\n",
      "Epoch 16/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3544 - acc: 0.5257 - val_loss: 1.4312 - val_acc: 0.4960\n",
      "Epoch 17/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3394 - acc: 0.5330 - val_loss: 1.4208 - val_acc: 0.5040\n",
      "Epoch 18/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3271 - acc: 0.5388 - val_loss: 1.4169 - val_acc: 0.5005\n",
      "Epoch 19/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3169 - acc: 0.5416 - val_loss: 1.4065 - val_acc: 0.5041\n",
      "Epoch 20/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.3055 - acc: 0.5432 - val_loss: 1.4034 - val_acc: 0.5072\n",
      "Epoch 21/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2905 - acc: 0.5495 - val_loss: 1.4017 - val_acc: 0.5093\n",
      "Epoch 22/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2798 - acc: 0.5543 - val_loss: 1.3947 - val_acc: 0.5103\n",
      "Epoch 23/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2654 - acc: 0.5567 - val_loss: 1.3981 - val_acc: 0.5120\n",
      "Epoch 24/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2572 - acc: 0.5604 - val_loss: 1.3886 - val_acc: 0.5105\n",
      "Epoch 25/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2478 - acc: 0.5654 - val_loss: 1.3872 - val_acc: 0.5144\n",
      "Epoch 26/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2350 - acc: 0.5692 - val_loss: 1.3853 - val_acc: 0.5153\n",
      "Epoch 27/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2261 - acc: 0.5749 - val_loss: 1.3811 - val_acc: 0.5180\n",
      "Epoch 28/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2185 - acc: 0.5733 - val_loss: 1.3821 - val_acc: 0.5163\n",
      "Epoch 29/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.2116 - acc: 0.5767 - val_loss: 1.3831 - val_acc: 0.5179\n",
      "Epoch 30/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1944 - acc: 0.5855 - val_loss: 1.3811 - val_acc: 0.5185\n",
      "Epoch 31/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1888 - acc: 0.5838 - val_loss: 1.3754 - val_acc: 0.5205\n",
      "Epoch 32/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1813 - acc: 0.5904 - val_loss: 1.3803 - val_acc: 0.5184\n",
      "Epoch 33/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1714 - acc: 0.5929 - val_loss: 1.3751 - val_acc: 0.5209\n",
      "Epoch 34/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1637 - acc: 0.5939 - val_loss: 1.3762 - val_acc: 0.5177\n",
      "Epoch 35/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1546 - acc: 0.5988 - val_loss: 1.3782 - val_acc: 0.5191\n",
      "Epoch 36/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1500 - acc: 0.5995 - val_loss: 1.3770 - val_acc: 0.5216\n",
      "Epoch 37/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1399 - acc: 0.6028 - val_loss: 1.3809 - val_acc: 0.5209\n",
      "Epoch 38/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1328 - acc: 0.6031 - val_loss: 1.3780 - val_acc: 0.5176\n",
      "Epoch 39/50\n",
      "42500/42500 [==============================] - 2s - loss: 1.1274 - acc: 0.6049 - val_loss: 1.3803 - val_acc: 0.5189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f894bf2a090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model0.add(Dropout(0.1))\n",
    "model0.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model0.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es0 = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "model0.fit(Xtr_std, Ytr_cat, nb_epoch=50, batch_size=1000, verbose=1, callbacks=[es0], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.518933333333\n"
     ]
    }
   ],
   "source": [
    "scores0 = model0.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 3s - loss: 2.0591 - acc: 0.2546 - val_loss: 1.8299 - val_acc: 0.3547\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.8518 - acc: 0.3401 - val_loss: 1.7406 - val_acc: 0.3855\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.7934 - acc: 0.3598 - val_loss: 1.6977 - val_acc: 0.4005\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.7566 - acc: 0.3764 - val_loss: 1.6622 - val_acc: 0.4132\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.7301 - acc: 0.3840 - val_loss: 1.6393 - val_acc: 0.4248\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.7105 - acc: 0.3933 - val_loss: 1.6166 - val_acc: 0.4344\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6925 - acc: 0.3979 - val_loss: 1.6001 - val_acc: 0.4397\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6783 - acc: 0.4039 - val_loss: 1.5835 - val_acc: 0.4467\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6619 - acc: 0.4113 - val_loss: 1.5718 - val_acc: 0.4476\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6515 - acc: 0.4146 - val_loss: 1.5640 - val_acc: 0.4556\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6419 - acc: 0.4207 - val_loss: 1.5496 - val_acc: 0.4573\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6297 - acc: 0.4225 - val_loss: 1.5436 - val_acc: 0.4589\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6184 - acc: 0.4288 - val_loss: 1.5330 - val_acc: 0.4635\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6114 - acc: 0.4301 - val_loss: 1.5263 - val_acc: 0.4648\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.6077 - acc: 0.4328 - val_loss: 1.5219 - val_acc: 0.4705\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5958 - acc: 0.4372 - val_loss: 1.5143 - val_acc: 0.4700\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5894 - acc: 0.4395 - val_loss: 1.5087 - val_acc: 0.4759\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5831 - acc: 0.4435 - val_loss: 1.5011 - val_acc: 0.4772\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5756 - acc: 0.4419 - val_loss: 1.4989 - val_acc: 0.4763\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5649 - acc: 0.4504 - val_loss: 1.4921 - val_acc: 0.4800\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5645 - acc: 0.4492 - val_loss: 1.4876 - val_acc: 0.4769\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5576 - acc: 0.4508 - val_loss: 1.4838 - val_acc: 0.4840\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5525 - acc: 0.4538 - val_loss: 1.4799 - val_acc: 0.4828\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5477 - acc: 0.4566 - val_loss: 1.4784 - val_acc: 0.4856\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5434 - acc: 0.4547 - val_loss: 1.4727 - val_acc: 0.4852\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5383 - acc: 0.4596 - val_loss: 1.4667 - val_acc: 0.4921\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5269 - acc: 0.4604 - val_loss: 1.4679 - val_acc: 0.4876\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5214 - acc: 0.4647 - val_loss: 1.4656 - val_acc: 0.4879\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5154 - acc: 0.4648 - val_loss: 1.4629 - val_acc: 0.4911\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5152 - acc: 0.4650 - val_loss: 1.4568 - val_acc: 0.4985\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5065 - acc: 0.4691 - val_loss: 1.4533 - val_acc: 0.4944\n",
      "Epoch 32/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.5017 - acc: 0.4704 - val_loss: 1.4521 - val_acc: 0.4953\n",
      "Epoch 33/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4983 - acc: 0.4718 - val_loss: 1.4526 - val_acc: 0.4931\n",
      "Epoch 34/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4936 - acc: 0.4724 - val_loss: 1.4457 - val_acc: 0.4957\n",
      "Epoch 35/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4919 - acc: 0.4761 - val_loss: 1.4477 - val_acc: 0.4931\n",
      "Epoch 36/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4851 - acc: 0.4766 - val_loss: 1.4414 - val_acc: 0.5008\n",
      "Epoch 37/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4877 - acc: 0.4752 - val_loss: 1.4432 - val_acc: 0.4933\n",
      "Epoch 38/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4734 - acc: 0.4778 - val_loss: 1.4362 - val_acc: 0.5033\n",
      "Epoch 39/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4738 - acc: 0.4807 - val_loss: 1.4356 - val_acc: 0.4980\n",
      "Epoch 40/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4736 - acc: 0.4822 - val_loss: 1.4354 - val_acc: 0.4980\n",
      "Epoch 41/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4650 - acc: 0.4847 - val_loss: 1.4336 - val_acc: 0.4969\n",
      "Epoch 42/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4611 - acc: 0.4855 - val_loss: 1.4300 - val_acc: 0.5056\n",
      "Epoch 43/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4565 - acc: 0.4872 - val_loss: 1.4305 - val_acc: 0.5004\n",
      "Epoch 44/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4542 - acc: 0.4850 - val_loss: 1.4263 - val_acc: 0.5051\n",
      "Epoch 45/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4508 - acc: 0.4897 - val_loss: 1.4256 - val_acc: 0.5044\n",
      "Epoch 46/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4442 - acc: 0.4910 - val_loss: 1.4249 - val_acc: 0.5055\n",
      "Epoch 47/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4442 - acc: 0.4923 - val_loss: 1.4226 - val_acc: 0.5067\n",
      "Epoch 48/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4400 - acc: 0.4933 - val_loss: 1.4240 - val_acc: 0.5025\n",
      "Epoch 49/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4363 - acc: 0.4944 - val_loss: 1.4201 - val_acc: 0.5027\n",
      "Epoch 50/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4349 - acc: 0.4934 - val_loss: 1.4198 - val_acc: 0.5043\n",
      "Epoch 51/100\n",
      "42500/42500 [==============================] - 4s - loss: 1.4284 - acc: 0.4958 - val_loss: 1.4134 - val_acc: 0.5036\n",
      "Epoch 52/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4258 - acc: 0.4974 - val_loss: 1.4189 - val_acc: 0.5048\n",
      "Epoch 53/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4256 - acc: 0.4997 - val_loss: 1.4130 - val_acc: 0.5013\n",
      "Epoch 54/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4221 - acc: 0.4974 - val_loss: 1.4150 - val_acc: 0.5031\n",
      "Epoch 55/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4198 - acc: 0.5014 - val_loss: 1.4159 - val_acc: 0.5056\n",
      "Epoch 56/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4187 - acc: 0.5000 - val_loss: 1.4152 - val_acc: 0.5057\n",
      "Epoch 57/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4099 - acc: 0.5025 - val_loss: 1.4136 - val_acc: 0.5069\n",
      "Epoch 58/100\n",
      "42500/42500 [==============================] - 2s - loss: 1.4094 - acc: 0.5043 - val_loss: 1.4147 - val_acc: 0.5055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f892b99bc90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es1 = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto', min_delta=0.001)\n",
    "model1.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es1], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s     \n",
      "\n",
      "Accuracy on validation set: 0.505466666698\n"
     ]
    }
   ],
   "source": [
    "scores1 = model1.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.8831 - acc: 0.3477 - val_loss: 1.6354 - val_acc: 0.4195\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.5786 - acc: 0.4493 - val_loss: 1.5573 - val_acc: 0.4536\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.4882 - acc: 0.4849 - val_loss: 1.5242 - val_acc: 0.4671\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.4250 - acc: 0.5096 - val_loss: 1.4850 - val_acc: 0.4827\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.3752 - acc: 0.5264 - val_loss: 1.4586 - val_acc: 0.4905\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.3289 - acc: 0.5439 - val_loss: 1.4398 - val_acc: 0.4980\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.2920 - acc: 0.5576 - val_loss: 1.4283 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.2558 - acc: 0.5696 - val_loss: 1.4141 - val_acc: 0.5079\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.2214 - acc: 0.5816 - val_loss: 1.4024 - val_acc: 0.5099\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.1900 - acc: 0.5942 - val_loss: 1.3945 - val_acc: 0.5151\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.1605 - acc: 0.6047 - val_loss: 1.3891 - val_acc: 0.5153\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.1316 - acc: 0.6145 - val_loss: 1.3798 - val_acc: 0.5209\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.1014 - acc: 0.6269 - val_loss: 1.3757 - val_acc: 0.5235\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.0762 - acc: 0.6342 - val_loss: 1.3750 - val_acc: 0.5243\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.0497 - acc: 0.6418 - val_loss: 1.3661 - val_acc: 0.5313\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 19s - loss: 1.0221 - acc: 0.6521 - val_loss: 1.3589 - val_acc: 0.5351\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.9994 - acc: 0.6617 - val_loss: 1.3598 - val_acc: 0.5384\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.9780 - acc: 0.6724 - val_loss: 1.3662 - val_acc: 0.5352\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.9516 - acc: 0.6796 - val_loss: 1.3629 - val_acc: 0.5407\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.9243 - acc: 0.6889 - val_loss: 1.3660 - val_acc: 0.5412\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.9057 - acc: 0.6946 - val_loss: 1.3674 - val_acc: 0.5391\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.8824 - acc: 0.7042 - val_loss: 1.3690 - val_acc: 0.5424\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.8596 - acc: 0.7117 - val_loss: 1.3703 - val_acc: 0.5409\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.8420 - acc: 0.7174 - val_loss: 1.3688 - val_acc: 0.5387\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.8202 - acc: 0.7268 - val_loss: 1.3915 - val_acc: 0.5415\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.8026 - acc: 0.7324 - val_loss: 1.3722 - val_acc: 0.5449\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 19s - loss: 0.7788 - acc: 0.7432 - val_loss: 1.3840 - val_acc: 0.5392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f894b7fe550>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(1024, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es2 = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "model2.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es2], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.539199999984\n"
     ]
    }
   ],
   "source": [
    "scores2 = model2.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 3s - loss: 2.2341 - acc: 0.1871 - val_loss: 2.1014 - val_acc: 0.2624\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.9865 - acc: 0.2934 - val_loss: 1.8864 - val_acc: 0.3292\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.8437 - acc: 0.3444 - val_loss: 1.7812 - val_acc: 0.3665\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.7661 - acc: 0.3707 - val_loss: 1.7171 - val_acc: 0.3901\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.7082 - acc: 0.3937 - val_loss: 1.6698 - val_acc: 0.4047\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.6673 - acc: 0.4081 - val_loss: 1.6307 - val_acc: 0.4208\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.6304 - acc: 0.4233 - val_loss: 1.5989 - val_acc: 0.4289\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5955 - acc: 0.4346 - val_loss: 1.5715 - val_acc: 0.4404\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5684 - acc: 0.4455 - val_loss: 1.5487 - val_acc: 0.4440\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5384 - acc: 0.4556 - val_loss: 1.5270 - val_acc: 0.4544\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.5158 - acc: 0.4645 - val_loss: 1.5070 - val_acc: 0.4652\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4911 - acc: 0.4732 - val_loss: 1.4916 - val_acc: 0.4723\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4733 - acc: 0.4794 - val_loss: 1.4774 - val_acc: 0.4752\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4509 - acc: 0.4867 - val_loss: 1.4658 - val_acc: 0.4760\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4380 - acc: 0.4901 - val_loss: 1.4498 - val_acc: 0.4819\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.4151 - acc: 0.5008 - val_loss: 1.4396 - val_acc: 0.4836\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3999 - acc: 0.5069 - val_loss: 1.4318 - val_acc: 0.4849\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3901 - acc: 0.5097 - val_loss: 1.4209 - val_acc: 0.4911\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3693 - acc: 0.5150 - val_loss: 1.4172 - val_acc: 0.4929\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3555 - acc: 0.5217 - val_loss: 1.4099 - val_acc: 0.4965\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3446 - acc: 0.5241 - val_loss: 1.4020 - val_acc: 0.4995\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3310 - acc: 0.5261 - val_loss: 1.3968 - val_acc: 0.4976\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3183 - acc: 0.5355 - val_loss: 1.3874 - val_acc: 0.5044\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.3067 - acc: 0.5360 - val_loss: 1.3865 - val_acc: 0.5049\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2933 - acc: 0.5420 - val_loss: 1.3803 - val_acc: 0.5076\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2873 - acc: 0.5469 - val_loss: 1.3742 - val_acc: 0.5063\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2712 - acc: 0.5525 - val_loss: 1.3699 - val_acc: 0.5140\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2620 - acc: 0.5550 - val_loss: 1.3636 - val_acc: 0.5127\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2510 - acc: 0.5568 - val_loss: 1.3618 - val_acc: 0.5140\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2407 - acc: 0.5618 - val_loss: 1.3602 - val_acc: 0.5124\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 3s - loss: 1.2330 - acc: 0.5667 - val_loss: 1.3631 - val_acc: 0.5165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89517acfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(100, init='uniform', activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es3 = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "model3.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es3], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.516533333349\n"
     ]
    }
   ],
   "source": [
    "scores3 = model3.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.3007 - acc: 0.1313 - val_loss: 2.2973 - val_acc: 0.1779\n",
      "Epoch 2/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.2892 - acc: 0.1876 - val_loss: 2.2725 - val_acc: 0.1868\n",
      "Epoch 3/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.2173 - acc: 0.1929 - val_loss: 2.1325 - val_acc: 0.2205\n",
      "Epoch 4/50\n",
      "42500/42500 [==============================] - 3s - loss: 2.0596 - acc: 0.2397 - val_loss: 1.9913 - val_acc: 0.2593\n",
      "Epoch 5/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.9599 - acc: 0.2768 - val_loss: 1.9103 - val_acc: 0.2907\n",
      "Epoch 6/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.8956 - acc: 0.3004 - val_loss: 1.8485 - val_acc: 0.3196\n",
      "Epoch 7/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.8434 - acc: 0.3215 - val_loss: 1.7937 - val_acc: 0.3409\n",
      "Epoch 8/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7972 - acc: 0.3398 - val_loss: 1.7569 - val_acc: 0.3579\n",
      "Epoch 9/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7617 - acc: 0.3591 - val_loss: 1.7216 - val_acc: 0.3697\n",
      "Epoch 10/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.7241 - acc: 0.3763 - val_loss: 1.6841 - val_acc: 0.3852\n",
      "Epoch 11/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6848 - acc: 0.3912 - val_loss: 1.6440 - val_acc: 0.4053\n",
      "Epoch 12/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6478 - acc: 0.4046 - val_loss: 1.6109 - val_acc: 0.4188\n",
      "Epoch 13/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.6180 - acc: 0.4187 - val_loss: 1.5885 - val_acc: 0.4256\n",
      "Epoch 14/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5935 - acc: 0.4282 - val_loss: 1.5705 - val_acc: 0.4352\n",
      "Epoch 15/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5671 - acc: 0.4368 - val_loss: 1.5525 - val_acc: 0.4376\n",
      "Epoch 16/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5458 - acc: 0.4456 - val_loss: 1.5336 - val_acc: 0.4488\n",
      "Epoch 17/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5225 - acc: 0.4543 - val_loss: 1.5184 - val_acc: 0.4545\n",
      "Epoch 18/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.5074 - acc: 0.4590 - val_loss: 1.5053 - val_acc: 0.4600\n",
      "Epoch 19/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4867 - acc: 0.4681 - val_loss: 1.4916 - val_acc: 0.4671\n",
      "Epoch 20/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4715 - acc: 0.4742 - val_loss: 1.4766 - val_acc: 0.4747\n",
      "Epoch 21/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4506 - acc: 0.4812 - val_loss: 1.4671 - val_acc: 0.4795\n",
      "Epoch 22/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4404 - acc: 0.4843 - val_loss: 1.4596 - val_acc: 0.4815\n",
      "Epoch 23/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4168 - acc: 0.4930 - val_loss: 1.4420 - val_acc: 0.4896\n",
      "Epoch 24/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.4064 - acc: 0.4980 - val_loss: 1.4380 - val_acc: 0.4893\n",
      "Epoch 25/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3893 - acc: 0.5030 - val_loss: 1.4366 - val_acc: 0.4908\n",
      "Epoch 26/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3773 - acc: 0.5042 - val_loss: 1.4257 - val_acc: 0.4957\n",
      "Epoch 27/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3639 - acc: 0.5132 - val_loss: 1.4168 - val_acc: 0.4989\n",
      "Epoch 28/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3502 - acc: 0.5176 - val_loss: 1.4096 - val_acc: 0.5040\n",
      "Epoch 29/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3369 - acc: 0.5224 - val_loss: 1.4042 - val_acc: 0.5027\n",
      "Epoch 30/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3221 - acc: 0.5301 - val_loss: 1.4068 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3106 - acc: 0.5306 - val_loss: 1.3939 - val_acc: 0.5055\n",
      "Epoch 32/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.3017 - acc: 0.5352 - val_loss: 1.3943 - val_acc: 0.5064\n",
      "Epoch 33/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2909 - acc: 0.5389 - val_loss: 1.3903 - val_acc: 0.5105\n",
      "Epoch 34/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2746 - acc: 0.5445 - val_loss: 1.3846 - val_acc: 0.5123\n",
      "Epoch 35/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2656 - acc: 0.5485 - val_loss: 1.3808 - val_acc: 0.5084\n",
      "Epoch 36/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2575 - acc: 0.5518 - val_loss: 1.3782 - val_acc: 0.5180\n",
      "Epoch 37/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2477 - acc: 0.5555 - val_loss: 1.3769 - val_acc: 0.5143\n",
      "Epoch 38/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2387 - acc: 0.5569 - val_loss: 1.3766 - val_acc: 0.5147\n",
      "Epoch 39/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2282 - acc: 0.5606 - val_loss: 1.3736 - val_acc: 0.5179\n",
      "Epoch 40/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2139 - acc: 0.5669 - val_loss: 1.3668 - val_acc: 0.5167\n",
      "Epoch 41/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.2051 - acc: 0.5680 - val_loss: 1.3695 - val_acc: 0.5188\n",
      "Epoch 42/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1991 - acc: 0.5705 - val_loss: 1.3639 - val_acc: 0.5195\n",
      "Epoch 43/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1895 - acc: 0.5755 - val_loss: 1.3776 - val_acc: 0.5200\n",
      "Epoch 44/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1756 - acc: 0.5798 - val_loss: 1.3755 - val_acc: 0.5160\n",
      "Epoch 45/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1731 - acc: 0.5808 - val_loss: 1.3702 - val_acc: 0.5201\n",
      "Epoch 46/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1588 - acc: 0.5888 - val_loss: 1.3687 - val_acc: 0.5261\n",
      "Epoch 47/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1498 - acc: 0.5877 - val_loss: 1.3635 - val_acc: 0.5260\n",
      "Epoch 48/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1472 - acc: 0.5889 - val_loss: 1.3589 - val_acc: 0.5241\n",
      "Epoch 49/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1363 - acc: 0.5920 - val_loss: 1.3639 - val_acc: 0.5228\n",
      "Epoch 50/50\n",
      "42500/42500 [==============================] - 3s - loss: 1.1295 - acc: 0.5977 - val_loss: 1.3762 - val_acc: 0.5187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8950ac2990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(100, init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(100, init='uniform', activation='relu'))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es4 = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "model4.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es4], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7456/7500 [============================>.] - ETA: 0s\n",
      "Accuracy on validation set: 0.497199999968\n"
     ]
    }
   ],
   "source": [
    "scores4 = model4.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.0959 - acc: 0.2365 - val_loss: 1.8748 - val_acc: 0.3336\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.8508 - acc: 0.3424 - val_loss: 1.7429 - val_acc: 0.3852\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.7512 - acc: 0.3771 - val_loss: 1.6691 - val_acc: 0.4099\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6903 - acc: 0.4026 - val_loss: 1.6207 - val_acc: 0.4295\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6464 - acc: 0.4182 - val_loss: 1.5849 - val_acc: 0.4381\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.6061 - acc: 0.4316 - val_loss: 1.5573 - val_acc: 0.4448\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.5802 - acc: 0.4408 - val_loss: 1.5322 - val_acc: 0.4641\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5448 - acc: 0.4543 - val_loss: 1.5087 - val_acc: 0.4673\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5210 - acc: 0.4635 - val_loss: 1.4914 - val_acc: 0.4697\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4999 - acc: 0.4719 - val_loss: 1.4746 - val_acc: 0.4839\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4725 - acc: 0.4786 - val_loss: 1.4607 - val_acc: 0.4891\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4552 - acc: 0.4863 - val_loss: 1.4440 - val_acc: 0.4944\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4331 - acc: 0.4950 - val_loss: 1.4302 - val_acc: 0.4983\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4116 - acc: 0.5009 - val_loss: 1.4205 - val_acc: 0.5037\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3946 - acc: 0.5087 - val_loss: 1.4072 - val_acc: 0.5067\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.3790 - acc: 0.5139 - val_loss: 1.4003 - val_acc: 0.5109\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3605 - acc: 0.5195 - val_loss: 1.3904 - val_acc: 0.5139\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3472 - acc: 0.5258 - val_loss: 1.3851 - val_acc: 0.5112\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3284 - acc: 0.5319 - val_loss: 1.3786 - val_acc: 0.5148\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3132 - acc: 0.5391 - val_loss: 1.3708 - val_acc: 0.5159\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3001 - acc: 0.5434 - val_loss: 1.3633 - val_acc: 0.5249\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2854 - acc: 0.5485 - val_loss: 1.3572 - val_acc: 0.5223\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2675 - acc: 0.5520 - val_loss: 1.3481 - val_acc: 0.5241\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2551 - acc: 0.5560 - val_loss: 1.3439 - val_acc: 0.5271\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2423 - acc: 0.5630 - val_loss: 1.3395 - val_acc: 0.5285\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2302 - acc: 0.5642 - val_loss: 1.3358 - val_acc: 0.5295\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2114 - acc: 0.5716 - val_loss: 1.3268 - val_acc: 0.5327\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2035 - acc: 0.5745 - val_loss: 1.3215 - val_acc: 0.5329\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1917 - acc: 0.5783 - val_loss: 1.3155 - val_acc: 0.5352\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1773 - acc: 0.5843 - val_loss: 1.3145 - val_acc: 0.5372\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1668 - acc: 0.5890 - val_loss: 1.3070 - val_acc: 0.5396\n",
      "Epoch 32/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1537 - acc: 0.5951 - val_loss: 1.3090 - val_acc: 0.5393\n",
      "Epoch 33/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1353 - acc: 0.5981 - val_loss: 1.2999 - val_acc: 0.5460\n",
      "Epoch 34/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1339 - acc: 0.5989 - val_loss: 1.3053 - val_acc: 0.5416\n",
      "Epoch 35/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1148 - acc: 0.6056 - val_loss: 1.3003 - val_acc: 0.5449\n",
      "Epoch 36/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1069 - acc: 0.6087 - val_loss: 1.2995 - val_acc: 0.5412\n",
      "Epoch 37/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0965 - acc: 0.6129 - val_loss: 1.2951 - val_acc: 0.5484\n",
      "Epoch 38/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0808 - acc: 0.6169 - val_loss: 1.2943 - val_acc: 0.5492\n",
      "Epoch 39/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0706 - acc: 0.6209 - val_loss: 1.2925 - val_acc: 0.5503\n",
      "Epoch 40/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0543 - acc: 0.6252 - val_loss: 1.2870 - val_acc: 0.5512\n",
      "Epoch 41/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0484 - acc: 0.6300 - val_loss: 1.2888 - val_acc: 0.5521\n",
      "Epoch 42/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0417 - acc: 0.6311 - val_loss: 1.2893 - val_acc: 0.5503\n",
      "Epoch 43/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0257 - acc: 0.6377 - val_loss: 1.2842 - val_acc: 0.5524\n",
      "Epoch 44/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0147 - acc: 0.6417 - val_loss: 1.2859 - val_acc: 0.5533\n",
      "Epoch 45/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0044 - acc: 0.6428 - val_loss: 1.2842 - val_acc: 0.5561\n",
      "Epoch 46/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9950 - acc: 0.6490 - val_loss: 1.2866 - val_acc: 0.5524\n",
      "Epoch 47/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9856 - acc: 0.6525 - val_loss: 1.2839 - val_acc: 0.5587\n",
      "Epoch 48/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9762 - acc: 0.6544 - val_loss: 1.2870 - val_acc: 0.5548\n",
      "Epoch 49/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9607 - acc: 0.6595 - val_loss: 1.2826 - val_acc: 0.5573\n",
      "Epoch 50/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9572 - acc: 0.6601 - val_loss: 1.2863 - val_acc: 0.5580\n",
      "Epoch 51/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9424 - acc: 0.6653 - val_loss: 1.2822 - val_acc: 0.5587\n",
      "Epoch 52/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9329 - acc: 0.6672 - val_loss: 1.2856 - val_acc: 0.5549\n",
      "Epoch 53/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9273 - acc: 0.6729 - val_loss: 1.2908 - val_acc: 0.5609\n",
      "Epoch 54/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9197 - acc: 0.6728 - val_loss: 1.2842 - val_acc: 0.5592\n",
      "Epoch 55/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9060 - acc: 0.6770 - val_loss: 1.2773 - val_acc: 0.5603\n",
      "Epoch 56/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8910 - acc: 0.6806 - val_loss: 1.2928 - val_acc: 0.5568\n",
      "Epoch 57/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8859 - acc: 0.6846 - val_loss: 1.2938 - val_acc: 0.5599\n",
      "Epoch 58/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.8736 - acc: 0.6910 - val_loss: 1.2867 - val_acc: 0.5592\n",
      "Epoch 59/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8684 - acc: 0.6909 - val_loss: 1.2915 - val_acc: 0.5620\n",
      "Epoch 60/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8570 - acc: 0.6964 - val_loss: 1.2916 - val_acc: 0.5617\n",
      "Epoch 61/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8514 - acc: 0.6984 - val_loss: 1.2981 - val_acc: 0.5591\n",
      "Epoch 62/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8343 - acc: 0.7053 - val_loss: 1.2992 - val_acc: 0.5617\n",
      "Epoch 63/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8326 - acc: 0.7028 - val_loss: 1.3087 - val_acc: 0.5591\n",
      "Epoch 64/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8234 - acc: 0.7080 - val_loss: 1.3084 - val_acc: 0.5613\n",
      "Epoch 65/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8150 - acc: 0.7095 - val_loss: 1.3096 - val_acc: 0.5580\n",
      "Epoch 66/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8034 - acc: 0.7129 - val_loss: 1.3159 - val_acc: 0.5619\n",
      "Epoch 67/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.8015 - acc: 0.7134 - val_loss: 1.3002 - val_acc: 0.5645\n",
      "Epoch 68/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7871 - acc: 0.7191 - val_loss: 1.3110 - val_acc: 0.5552\n",
      "Epoch 69/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7773 - acc: 0.7226 - val_loss: 1.3206 - val_acc: 0.5640\n",
      "Epoch 70/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7729 - acc: 0.7251 - val_loss: 1.3270 - val_acc: 0.5564\n",
      "Epoch 71/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7686 - acc: 0.7261 - val_loss: 1.3184 - val_acc: 0.5592\n",
      "Epoch 72/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7591 - acc: 0.7286 - val_loss: 1.3176 - val_acc: 0.5612\n",
      "Epoch 73/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7505 - acc: 0.7316 - val_loss: 1.3318 - val_acc: 0.5579\n",
      "Epoch 74/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7364 - acc: 0.7351 - val_loss: 1.3379 - val_acc: 0.5617\n",
      "Epoch 75/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7351 - acc: 0.7387 - val_loss: 1.3271 - val_acc: 0.5647\n",
      "Epoch 76/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7258 - acc: 0.7402 - val_loss: 1.3404 - val_acc: 0.5583\n",
      "Epoch 77/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7225 - acc: 0.7417 - val_loss: 1.3489 - val_acc: 0.5629\n",
      "Epoch 78/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7128 - acc: 0.7464 - val_loss: 1.3386 - val_acc: 0.5632\n",
      "Epoch 79/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.7020 - acc: 0.7500 - val_loss: 1.3472 - val_acc: 0.5600\n",
      "Epoch 80/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6978 - acc: 0.7515 - val_loss: 1.3486 - val_acc: 0.5608\n",
      "Epoch 81/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6911 - acc: 0.7549 - val_loss: 1.3592 - val_acc: 0.5608\n",
      "Epoch 82/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6867 - acc: 0.7559 - val_loss: 1.3449 - val_acc: 0.5648\n",
      "Epoch 83/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6730 - acc: 0.7596 - val_loss: 1.3698 - val_acc: 0.5632\n",
      "Epoch 84/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6606 - acc: 0.7630 - val_loss: 1.3716 - val_acc: 0.5563\n",
      "Epoch 85/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.6584 - acc: 0.7664 - val_loss: 1.3655 - val_acc: 0.5645\n",
      "Epoch 86/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6580 - acc: 0.7675 - val_loss: 1.3660 - val_acc: 0.5581\n",
      "Epoch 87/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6433 - acc: 0.7697 - val_loss: 1.3714 - val_acc: 0.5632\n",
      "Epoch 88/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6381 - acc: 0.7736 - val_loss: 1.3889 - val_acc: 0.5613\n",
      "Epoch 89/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6369 - acc: 0.7732 - val_loss: 1.3897 - val_acc: 0.5567\n",
      "Epoch 90/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6312 - acc: 0.7756 - val_loss: 1.3972 - val_acc: 0.5592\n",
      "Epoch 91/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6213 - acc: 0.7776 - val_loss: 1.3987 - val_acc: 0.5533\n",
      "Epoch 92/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6167 - acc: 0.7817 - val_loss: 1.3894 - val_acc: 0.5567\n",
      "Epoch 93/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.6044 - acc: 0.7816 - val_loss: 1.4043 - val_acc: 0.5601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89481cb210>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(512, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, init='uniform', activation='relu'))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model5.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es5 = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto')\n",
    "model5.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, callbacks=[es5], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s     \n",
      "\n",
      "Accuracy on validation set: 0.560133333333\n"
     ]
    }
   ],
   "source": [
    "scores5 = model5.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores5[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.2635 - acc: 0.1674 - val_loss: 2.1625 - val_acc: 0.2507\n",
      "Epoch 2/100\n",
      "42500/42500 [==============================] - 11s - loss: 2.0543 - acc: 0.2545 - val_loss: 1.9176 - val_acc: 0.3077\n",
      "Epoch 3/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.9012 - acc: 0.3103 - val_loss: 1.8112 - val_acc: 0.3493\n",
      "Epoch 4/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.8187 - acc: 0.3455 - val_loss: 1.7394 - val_acc: 0.3763\n",
      "Epoch 5/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.7565 - acc: 0.3685 - val_loss: 1.6831 - val_acc: 0.3908\n",
      "Epoch 6/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.7084 - acc: 0.3890 - val_loss: 1.6437 - val_acc: 0.4061\n",
      "Epoch 7/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.6619 - acc: 0.4088 - val_loss: 1.6096 - val_acc: 0.4221\n",
      "Epoch 8/100\n",
      "42500/42500 [==============================] - 13s - loss: 1.6266 - acc: 0.4233 - val_loss: 1.5815 - val_acc: 0.4309\n",
      "Epoch 9/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.5961 - acc: 0.4315 - val_loss: 1.5517 - val_acc: 0.4424\n",
      "Epoch 10/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5651 - acc: 0.4464 - val_loss: 1.5313 - val_acc: 0.4503\n",
      "Epoch 11/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5358 - acc: 0.4530 - val_loss: 1.5092 - val_acc: 0.4616\n",
      "Epoch 12/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.5107 - acc: 0.4660 - val_loss: 1.4931 - val_acc: 0.4679\n",
      "Epoch 13/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4857 - acc: 0.4739 - val_loss: 1.4723 - val_acc: 0.4767\n",
      "Epoch 14/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.4603 - acc: 0.4864 - val_loss: 1.4576 - val_acc: 0.4835\n",
      "Epoch 15/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4365 - acc: 0.4919 - val_loss: 1.4395 - val_acc: 0.4919\n",
      "Epoch 16/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.4115 - acc: 0.5007 - val_loss: 1.4275 - val_acc: 0.4936\n",
      "Epoch 17/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3904 - acc: 0.5100 - val_loss: 1.4189 - val_acc: 0.5005\n",
      "Epoch 18/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3669 - acc: 0.5168 - val_loss: 1.4071 - val_acc: 0.4997\n",
      "Epoch 19/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3479 - acc: 0.5243 - val_loss: 1.4018 - val_acc: 0.5012\n",
      "Epoch 20/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3285 - acc: 0.5318 - val_loss: 1.3849 - val_acc: 0.5092\n",
      "Epoch 21/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.3056 - acc: 0.5398 - val_loss: 1.3834 - val_acc: 0.5119\n",
      "Epoch 22/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2868 - acc: 0.5435 - val_loss: 1.3665 - val_acc: 0.5144\n",
      "Epoch 23/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2667 - acc: 0.5532 - val_loss: 1.3600 - val_acc: 0.5196\n",
      "Epoch 24/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2530 - acc: 0.5542 - val_loss: 1.3580 - val_acc: 0.5168\n",
      "Epoch 25/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2273 - acc: 0.5657 - val_loss: 1.3510 - val_acc: 0.5211\n",
      "Epoch 26/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.2114 - acc: 0.5698 - val_loss: 1.3391 - val_acc: 0.5269\n",
      "Epoch 27/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.1922 - acc: 0.5786 - val_loss: 1.3407 - val_acc: 0.5304\n",
      "Epoch 28/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.1734 - acc: 0.5854 - val_loss: 1.3341 - val_acc: 0.5311\n",
      "Epoch 29/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1583 - acc: 0.5890 - val_loss: 1.3292 - val_acc: 0.5307\n",
      "Epoch 30/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1374 - acc: 0.5944 - val_loss: 1.3290 - val_acc: 0.5341\n",
      "Epoch 31/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1175 - acc: 0.6030 - val_loss: 1.3314 - val_acc: 0.5303\n",
      "Epoch 32/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.1028 - acc: 0.6085 - val_loss: 1.3221 - val_acc: 0.5387\n",
      "Epoch 33/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0844 - acc: 0.6165 - val_loss: 1.3266 - val_acc: 0.5375\n",
      "Epoch 34/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0755 - acc: 0.6199 - val_loss: 1.3245 - val_acc: 0.5360\n",
      "Epoch 35/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.0525 - acc: 0.6263 - val_loss: 1.3222 - val_acc: 0.5413\n",
      "Epoch 36/100\n",
      "42500/42500 [==============================] - 12s - loss: 1.0426 - acc: 0.6293 - val_loss: 1.3228 - val_acc: 0.5428\n",
      "Epoch 37/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0170 - acc: 0.6395 - val_loss: 1.3337 - val_acc: 0.5340\n",
      "Epoch 38/100\n",
      "42500/42500 [==============================] - 11s - loss: 1.0004 - acc: 0.6464 - val_loss: 1.3327 - val_acc: 0.5400\n",
      "Epoch 39/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9891 - acc: 0.6476 - val_loss: 1.3265 - val_acc: 0.5419\n",
      "Epoch 40/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9701 - acc: 0.6544 - val_loss: 1.3448 - val_acc: 0.5437\n",
      "Epoch 41/100\n",
      "42500/42500 [==============================] - 12s - loss: 0.9540 - acc: 0.6595 - val_loss: 1.3278 - val_acc: 0.5484\n",
      "Epoch 42/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9377 - acc: 0.6664 - val_loss: 1.3411 - val_acc: 0.5449\n",
      "Epoch 43/100\n",
      "42500/42500 [==============================] - 11s - loss: 0.9232 - acc: 0.6696 - val_loss: 1.3420 - val_acc: 0.5471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f894aa30c90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(512, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.1))\n",
    "model6.add(Dense(128, init='uniform', activation='relu'))\n",
    "model6.add(Dropout(0.6))\n",
    "model6.add(Dense(10, init='uniform', activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model6.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "es6 = EarlyStopping(monitor='val_accu', patience=10, verbose=0, mode='auto')\n",
    "model6.fit(Xtr_std, Ytr_cat, nb_epoch=100, batch_size=1000, verbose=1, callbacks=[es6], validation_data=(Xval_std, Yval_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s     \n",
      "\n",
      "Accuracy on validation set: 0.547066666635\n"
     ]
    }
   ],
   "source": [
    "scores6 = model6.evaluate(Xval_std, Yval_cat)\n",
    "print \"\\nAccuracy on validation set: {}\".format(scores6[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from top_level_features import hog_features\n",
    "from top_level_features import color_histogram_hsv\n",
    "from top_level_features import extract_features\n",
    "\n",
    "Xtr, Ytr, Xval, Yval, Xte, Yte = load_CIFAR10('data')\n",
    "features = extract_features(Xtr,[hog_features]) #extrae hog features\n",
    "features = extract_features(Xtr,[color_histogram_hsv]) #extrae histogramas de color\n",
    "features = extract_features(Xtr,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "\n",
    "print Xtr.shape\n",
    "print features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
