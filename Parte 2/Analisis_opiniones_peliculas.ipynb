{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Construcción del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el conjunto de entrenamiento como el de pruebas, poseen 3554 registros para cada clase. Dichas clases se llaman \"Sentiment\" y \"Text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Función word_extractor\n",
    "\n",
    "La función word_extractor utiliza stemming para la extracción de trozos de textos de una frase. El stemming es un proceso heurístico que corta la derivación de las palabras para encontrar la raíz. Por ejemplo autómata, automático, automatizado se reducen a autómata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def word_extractor(text, stemming=True):\n",
    "    if stemming is True:\n",
    "        wordstemmer = PorterStemmer()\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ wordstemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "    else:\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "        \n",
    "#Con stemming\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se presenta es la extracción de trozos de texto en una frase. Al usar stemming para dicha tarea se puede apreciar en el output que se muestra la tarea en presente simple, lo que muestra que el stemming usa un vocabulario reducido al ignorar palabras como \"eating\" y \"loved\", ya que éstas no corresponden al presente simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#Sin stemming\n",
    "print word_extractor(\"I love to eat cake\", stemming=False)\n",
    "print word_extractor(\"I love eating cake\", stemming=False)\n",
    "print word_extractor(\"I loved eating the cake\", stemming=False)\n",
    "print word_extractor(\"I do not love eating cake\", stemming=False)\n",
    "print word_extractor(\"I don't love eating cake\", stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se ejecutó word_extractor sin usar stemming y se puede apreciar que muestra las palabras exactas, lo que se puede concluir que sin usar stemming se obtiene resultados mejores que con stemming debido a que no se redujo el vocabulario sin el uso de stemming.\n",
    "\n",
    "En resumen, si se consideran los textos “I love eating cake” y “I loved eating the cake”, con stemming se consigue “love eat cake” para ambos casos, mientras que sin stemming se obtiene “love eating cake” y “loved eating cake”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c) Función word_extractor2\n",
    "\n",
    "La función word_extractor2 utiliza el lematizador para extraer trozos de texto de una frase. La lematización es bastante similar al stemming, en el sentido que reducen las formas infleccionales de las palabras a una base común o raíz. Pero en el caso de la lematización y a partir de la implementación de *nltk*, se hace un chequeo de la forma reducida en el corpus de *WordNet*. Si no está en este último, se regresa la palabra original. En consecuencia, la lematización es un proceso más complejo que el stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#la variavle stopwords indica si el lematizador usa stopwords.\n",
    "def word_extractor2(text, stopWords=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    if stopWords is True:\n",
    "        commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "                  for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if stopWords is True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado, a diferencia de la función word_extractor que usaba stemming para poder extraer trozos de palabras de una frase, la función word_extractor2 que usa lematización para dicho objetivo devuelve cada trozo de palabra exacta, lo que permite un uso de vocabulario más amplio que usando stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d) CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#Conjunto de entrenamiento\n",
    "tags_train = []\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_train.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Conjunto de pruebas\n",
    "tags_test = []\n",
    "dist=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_test.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código que contiene el CountVectorizer tiene como objetivo guardar la cantidad de veces que aparece cierta palabra/número en el conjunto de entrenamiento/prueba. Las palabras más frecuentes en el conjunto de entrenamiento/pruebas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de entrenaiento:\n",
      "\n",
      "1) film (566)\n",
      "2) movie (481)\n",
      "3) one (246)\n",
      "4) like (245)\n",
      "5) ha (224)\n",
      "6) make (183)\n",
      "7) story (176)\n",
      "8) character (163)\n",
      "9) comedy (145)\n",
      "10) time (143)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_train.sort()\n",
    "tags_train[:] = tags_train[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de entrenaiento:\\n\"\n",
    "for i in range(0,10):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_train[i][1], tags_train[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de prueba:\n",
      "\n",
      "1) film (558)\n",
      "2) movie (540)\n",
      "3) one (250)\n",
      "4) ha (238)\n",
      "5) like (230)\n",
      "6) story (197)\n",
      "7) character (175)\n",
      "8) time (165)\n",
      "9) make (161)\n",
      "10) comedy (134)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_test.sort()\n",
    "tags_test[:] = tags_test[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de prueba:\\n\"\n",
    "for i in range(0,10):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_test[i][1], tags_test[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Desempeño de un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "dict_bernoulli_binario = []\n",
    "dict_multinomial = []\n",
    "dict_log = []\n",
    "dict_svm = []\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))\n",
    "    \n",
    "    #guarda las métricas de cada método para construir gráficos comparativos más adelante.\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(yt, model.predict(xt))\n",
    "    \n",
    "    if text == 'BernoulliNB':\n",
    "        dict_bernoulli_binario.append(acc_tr)\n",
    "        dict_bernoulli_binario.append(acc_test)\n",
    "        dict_bernoulli_binario.append(np.mean(precision))\n",
    "        dict_bernoulli_binario.append(np.mean(recall))\n",
    "        dict_bernoulli_binario.append(np.mean(fscore))\n",
    "    elif text == 'MULTINOMIAL':\n",
    "        dict_multinomial.append(acc_tr)\n",
    "        dict_multinomial.append(acc_test)\n",
    "        dict_multinomial.append(np.mean(precision))\n",
    "        dict_multinomial.append(np.mean(recall))\n",
    "        dict_multinomial.append(np.mean(fscore))\n",
    "    elif text == 'LOGISTIC':\n",
    "        dict_log.append(acc_tr)\n",
    "        dict_log.append(acc_test)\n",
    "        dict_log.append(np.mean(precision))\n",
    "        dict_log.append(np.mean(recall))\n",
    "        dict_log.append(np.mean(fscore))\n",
    "    elif text == 'SVM':\n",
    "        dict_svm.append(acc_tr)\n",
    "        dict_svm.append(acc_test)\n",
    "        dict_svm.append(np.mean(precision))\n",
    "        dict_svm.append(np.mean(recall))\n",
    "        dict_svm.append(np.mean(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas que calcula el método classification_report son las siguientes: precision, recall y F1-score, tal y como se muestra en el output generado usando el clasificador Bayesiano Ingenuo/Multinomial.\n",
    "\n",
    "- Precision es la cantidad de resultados positivos correctos divididos por la cantidad total de resultados positivos\n",
    "- Recall corresponde a la cantidad de resultados positivos correctos dividido por el número de resultados positivos que se debería obtener.\n",
    "- El F1-score es el promedio ponderado de recall y precision. La mejor puntuación corresponde a 1 y la peor corresponde a 0. La fórmula para calcular el F1-score es el siguiente:\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Clasificador Bayesiano Ingenuo (Binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.04199754  0.95800246] the plan to make enough into �an inspiring tale of survival wrapped in the heart-pounding suspense of a stylish psychological thriller' has flopped as surely as a souffl� gone wrong .\n",
      "\n",
      "[ 0.4313423  0.5686577] borrows a bit from the classics \" wait until dark \" and \" extremities \" . . . but in terms of its style , the movie is in a class by itself .\n",
      "\n",
      "[ 0.98459667  0.01540333] unless you come in to the film with a skateboard under your arm , you're going to feel like you weren't invited to the party .\n",
      "\n",
      "[ 0.83019561  0.16980439] a serious movie with serious ideas . but seriously , folks , it doesn't work .\n",
      "\n",
      "[ 0.97451387  0.02548613] cassavetes thinks he's making dog day afternoon with a cause , but all he's done is to reduce everything he touches to a shrill , didactic cartoon .\n",
      "\n",
      "[ 0.01888243  0.98111757] [barry] gives assassin a disquieting authority .\n",
      "\n",
      "[ 0.98185295  0.01814705] the next generation of mob movie . part low rent godfather . part three stooges .\n",
      "\n",
      "[ 0.00832827  0.99167173] dogtown & z-boys evokes the blithe rebel fantasy with the kind of insouciance embedded in the sexy demise of james dean .\n",
      "\n",
      "[ 0.20689999  0.79310001] the movie generates plot points with a degree of randomness usually achieved only by lottery drawing .\n",
      "\n",
      "[ 0.00948383  0.99051617] waydowntown may not be an important movie , or even a good one , but it provides a nice change of mindless pace in collision with the hot oscar season currently underway .\n",
      "\n",
      "[ 0.04787404  0.95212596] it's like an old warner bros . costumer jived with sex -- this could be the movie errol flynn always wanted to make , though bette davis , cast as joan , would have killed him .\n",
      "\n",
      "[ 0.58609367  0.41390633] i liked this film a lot . . .\n",
      "\n",
      "[ 0.31444339  0.68555661] all of the elements are in place for a great film noir , but director george hickenlooper's approach to the material is too upbeat .\n",
      "\n",
      "[ 0.38412551  0.61587449] god is great , the movie's not .\n",
      "\n",
      "[ 0.52525495  0.47474505] a film so tedious that it is impossible to care whether that boast is true or not .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.40157468  0.59842532] as played by ryan gosling , danny is a frighteningly fascinating contradiction .\n",
      "\n",
      "[ 0.78957893  0.21042107] wonder of wonders -- a teen movie with a humanistic message .\n",
      "\n",
      "[ 0.24704298  0.75295702] the picture runs a mere 84 minutes , but it's no glance . it's a head-turner -- thoughtfully written , beautifully read and , finally , deeply humanizing .\n",
      "\n",
      "[ 0.74828258  0.25171742] this is the first film i've ever seen that had no obvious directing involved .\n",
      "\n",
      "[ 0.00145052  0.99854948] quiet , adult and just about more stately than any contemporary movie this year . . . a true study , a film with a questioning heart and mind that isn't afraid to admit it doesn't have all the answers .\n",
      "\n",
      "[ 0.9888247  0.0111753] this version of h . g . wells' time machine was directed by h . g . wells' great-grandson . they should have found orson welles' great-grandson .\n",
      "\n",
      "[ 0.28692763  0.71307237] beautifully produced .\n",
      "\n",
      "[ 0.02953787  0.97046213] still rapturous after all these years , cinema paradiso stands as one of the great films about movie love .\n",
      "\n",
      "[ 0.65495609  0.34504391] the movie doesn't add anything fresh to the myth .\n",
      "\n",
      "[ 0.64627365  0.35372635] one of creepiest , scariest movies to come along in a long , long time , easily rivaling blair witch or the others .\n",
      "\n",
      "[ 0.19572945  0.80427055] thoroughly engrossing and ultimately tragic .\n",
      "\n",
      "[ 0.13228783  0.86771217] not a film to rival to live , but a fine little amuse-bouche to keep your appetite whetted .\n",
      "\n",
      "[ 0.37183905  0.62816095] though it's become almost redundant to say so , major kudos go to leigh for actually casting people who look working-class .\n",
      "\n",
      "[ 0.13509995  0.86490005] is \" ballistic \" worth the price of admission ? absolutely not . it sucked . would i see it again ? please see previous answer .\n",
      "\n",
      "[ 0.44099181  0.55900819] the story of trouble every day . . . is so sketchy it amounts to little more than preliminary notes for a science-fiction horror film , and the movie's fragmentary narrative style makes piecing the story together frustrating difficult .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.878728\n",
      "Test Accuracy BernoulliNB: 0.701098\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.68      0.70      1803\n",
      "          -       0.69      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "[ 0.79896113  0.20103887] not even the hanson brothers can save it\n",
      "\n",
      "[ 0.87653986  0.12346014] absurdities and clich�s accumulate like lint in a fat man's navel .\n",
      "\n",
      "[ 0.31941688  0.68058312] narc is all menace and atmosphere .\n",
      "\n",
      "[ 0.96621417  0.03378583] another big , dumb action movie in the vein of xxx , the transporter is riddled with plot holes big enough for its titular hero to drive his sleek black bmw through .\n",
      "\n",
      "[ 0.03344819  0.96655181] becomes a fascinating study of isolation and frustration that successfully recreates both the physical setting and emotional tensions of the papin sisters .\n",
      "\n",
      "[ 0.24342471  0.75657529] eight legged freaks ? no big hairy deal .\n",
      "\n",
      "[ 0.54858767  0.45141233] both an admirable reconstruction of terrible events , and a fitting memorial to the dead of that day , and of the thousands thereafter .\n",
      "\n",
      "[ 0.42752802  0.57247198] a perceptive , good-natured movie .\n",
      "\n",
      "[ 0.48642918  0.51357082] no surprises .\n",
      "\n",
      "[ 0.65102166  0.34897834] nothing sticks , really , except a lingering creepiness one feels from being dragged through a sad , sordid universe of guns , drugs , avarice and damaged dreams .\n",
      "\n",
      "[ 0.34780413  0.65219587] like mike is a slight and uninventive movie : like the exalted michael jordan referred to in the title , many can aspire but none can equal .\n",
      "\n",
      "[ 0.02433511  0.97566489] payne constructs a hilarious ode to middle america and middle age with this unlikely odyssey , featuring a pathetic , endearing hero who is all too human .\n",
      "\n",
      "[ 0.75718864  0.24281136] this is a superior horror flick .\n",
      "\n",
      "[ 0.50793296  0.49206704] appropriately cynical social commentary aside , #9 never quite ignites .\n",
      "\n",
      "[ 0.26698972  0.73301028] it's a sometimes interesting remake that doesn't compare to the brilliant original .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resumen, al usar el Clasificador Bayesiano Ingenuo Binario, se obtuvieron los siguientes resultados:\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.958638   |         0.955262               |  0.878728                   \n",
    "  Test accuracy     | 0.738531   |         0.748663               |  0.701098              \n",
    "  Precision         | 0.74       |         0.75                   |  0.70             \n",
    "  Recall            | 0.74       |         0.75                   |  0.70             \n",
    "  F1-score          | 0.74       |         0.75                   |  0.70             \n",
    "  \n",
    "En términos generales, se obtienen buenos resultados utilizando lematización y stemming, siendo este último un poco mejor. Al trabajar sin stopwords el procesamiento se vuelve más lento al aumentar el vocabulario pero a pesar de eso, se obtienen buenos resultados. Sin embargo, las palabras más frecuentes son artículos, pronombres y preposiciones en su mayoría, lo que causa la pérdida del poder de análisis en los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Clasificador Bayesiano Ingenuo Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.5015401  0.4984599] 'this movie sucks . '\n",
      "\n",
      "[ 0.37561196  0.62438804] not the great american comedy , but if you liked the previous movies in the series , you'll have a good time with this one too .\n",
      "\n",
      "[ 0.82668558  0.17331442] you don't have to be an especially tough grader to give a charitable b-minus to the emperor's club .\n",
      "\n",
      "[ 0.34138331  0.65861669] bittersweet comedy/drama full of life , hand gestures , and some really adorable italian guys .\n",
      "\n",
      "[ 0.86048873  0.13951127] it has the right approach and the right opening premise , but it lacks the zest and it goes for a plot twist instead of trusting the material .\n",
      "\n",
      "[ 0.86144939  0.13855061] a sleek advert for youthful anomie that never quite equals the sum of its pretensions .\n",
      "\n",
      "[ 0.02573967  0.97426033] amazing ! a college story that works even without vulgarity , sex scenes , and cussing !\n",
      "\n",
      "[ 0.12712554  0.87287446] what makes barbershop so likable , with all its flaws , is that it has none of the pushiness and decibel volume of most contemporary comedies .\n",
      "\n",
      "[ 0.54143966  0.45856034] beautifully reclaiming the story of carmen and recreating it an in an african idiom .\n",
      "\n",
      "[ 0.02123671  0.97876329] nonchalantly freaky and uncommonly pleasurable , warm water may well be the year's best and most unpredictable comedy .\n",
      "\n",
      "[ 0.49970897  0.50029103] . . . wise and elegiac . . .\n",
      "\n",
      "[ 0.15135699  0.84864301] a no-holds-barred cinematic treat .\n",
      "\n",
      "[ 0.78909318  0.21090682] it's neither as sappy as big daddy nor as anarchic as happy gilmore or the waterboy , but it has its moments .\n",
      "\n",
      "[ 0.36799322  0.63200678] one of the best looking and stylish animated movies in quite a while . . .\n",
      "\n",
      "[ 0.12202296  0.87797704] it gives devastating testimony to both people's capacity for evil and their heroic capacity for good .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.14282098  0.85717902] will probably stay in the shadow of its two older , more accessible qatsi siblings .\n",
      "\n",
      "[ 0.89031275  0.10968725] yes , i have given this movie a rating of zero . but fans of the show should not consider this a diss . consider it 'perfection . '\n",
      "\n",
      "[ 0.94201887  0.05798113] lawrence should stick to his day job . he's a better actor than a standup comedian .\n",
      "\n",
      "[  9.99558318e-01   4.41682403e-04] a tired , unnecessary retread . . . a stale copy of a picture that wasn't all that great to begin with .\n",
      "\n",
      "[ 0.53648151  0.46351849] does point the way for adventurous indian filmmakers toward a crossover into nonethnic markets .\n",
      "\n",
      "[ 0.8344256  0.1655744] leaves you with a knot in your stomach , its power is undercut by its own head-banging obviousness .\n",
      "\n",
      "[ 0.15342413  0.84657587] large budget notwithstanding , the movie is such a blip on the year's radar screen that it's tempting just to go with it for the ride . but this time , the old mib label stands for milder isn't better .\n",
      "\n",
      "[ 0.98503613  0.01496387] writer/director john mckay ignites some charming chemistry between kate and jed but , when he veers into sodden melodrama , punctuated by violins , it's disastrous and kate's jealous female friends become downright despicable .\n",
      "\n",
      "[  2.18605926e-04   9.99781394e-01] a compelling coming-of-age drama about the arduous journey of a sensitive young girl through a series of foster homes and a fierce struggle to pull free from her dangerous and domineering mother's hold over her .\n",
      "\n",
      "[ 0.93312564  0.06687436] the movie isn't painfully bad , something to be 'fully experienced' ; it's just tediously bad , something to be fully forgotten .\n",
      "\n",
      "[ 0.24753489  0.75246511] like all of egoyan's work , ararat is fiercely intelligent and uncommonly ambitious .\n",
      "\n",
      "[ 0.59729234  0.40270766] steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "[ 0.03187479  0.96812521] there's a disturbing 'great white hope' undertone to the other side of heaven that subtly undermines its message of christian love and compassion .\n",
      "\n",
      "[ 0.67783005  0.32216995] . . . grows decidedly flimsier with its many out-sized , out of character and logically porous action set pieces .\n",
      "\n",
      "[ 0.90680767  0.09319233] there's something with potential here , but the movie decides , like lavinia , to go the conservative route .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.882949\n",
      "Test Accuracy MULTINOMIAL: 0.705319\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.70      0.71      1803\n",
      "          -       0.70      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "[ 0.89626185  0.10373815] for anyone who grew up on disney's 1950 treasure island , or remembers the 1934 victor fleming classic , this one feels like an impostor .\n",
      "\n",
      "[ 0.49516061  0.50483939] it tells more than it shows .\n",
      "\n",
      "[ 0.73341015  0.26658985] as broad and cartoonish as the screenplay is , there is an accuracy of observation in the work of the director , frank novak , that keeps the film grounded in an undeniable social realism .\n",
      "\n",
      "[ 0.91335102  0.08664898] this version of h . g . wells' time machine was directed by h . g . wells' great-grandson . they should have found orson welles' great-grandson .\n",
      "\n",
      "[ 0.81100419  0.18899581] as vulgar as it is banal .\n",
      "\n",
      "[ 0.91944106  0.08055894] suffers from a decided lack of creative storytelling .\n",
      "\n",
      "[ 0.62913241  0.37086759] just about all of the film is confusing on one level or another , making ararat far more demanding than it needs to be .\n",
      "\n",
      "[ 0.95937263  0.04062737] when the screenwriter responsible for one of the worst movies of one year directs an equally miserable film the following year , you'd have a hard time believing it was just coincidence .\n",
      "\n",
      "[ 0.6801548  0.3198452] if you're not a prepubescent girl , you'll be laughing at britney spears' movie-starring debut whenever it doesn't have you impatiently squinting at your watch .\n",
      "\n",
      "[ 0.31398997  0.68601003] fear dot com is more frustrating than a modem that disconnects every 10 seconds .\n",
      "\n",
      "[ 0.31605969  0.68394031] while not quite a comedy , the film tackles its relatively serious subject with an open mind and considerable good cheer , and is never less than engaging .\n",
      "\n",
      "[ 0.89418183  0.10581817] it's all arty and jazzy and people sit and stare and turn away from one another instead of talking and it's all about the silences and if you're into that , have at it .\n",
      "\n",
      "[ 0.16056064  0.83943936] this clever caper movie has twists worthy of david mamet and is enormous fun for thinking audiences .\n",
      "\n",
      "[ 0.08016267  0.91983733] whatever one makes of its political edge , this is beautiful filmmaking from one of french cinema's master craftsmen .\n",
      "\n",
      "[ 0.09350121  0.90649879] who needs mind-bending drugs when they can see this , the final part of the 'qatsi' trilogy , directed by godfrey reggio , with music by philip glass ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resumen, al usar el Clasificador Bayesiano Ingenuo Multinomial, se obtuvieron los siguientes resultados:\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.959482   |         0.955543               |  0.882949                   \n",
    "  Test accuracy     | 0.740782   |         0.747537               |  0.705319              \n",
    "  Precision         | 0.74       |         0.75                   |  0.71             \n",
    "  Recall            | 0.74       |         0.75                   |  0.71             \n",
    "  F1-score          | 0.74       |         0.75                   |  0.71             \n",
    "  \n",
    "La conclusión que se obtiene a partir de estos resultados es la misma que para el caso del ejercicio f), debida a las mismas razones planteadas anteriormente en dicho ejercicio, es decir, se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un mejor resultado. Al trabajar sin stopwords el efecto que produce es que el procesamiento se vuelve más lento, debido al aumento en el vocabulario pero aún así se obtienen buenos resultados. No obstante, las palabras más frecuentes son artículos, pronombres y preposiciones en su mayoría perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Regresión Logı́stica Regularizado\n",
    "\n",
    "La regularización permite controlar el efecto de los estimadores en la predicción, es decir, el aporte que tienen\n",
    "estos. Para el caso del algoritmo de Regresión logística (ocurre lo mismo en SVM lineal) utiliza como parámetro\n",
    "el valor inverso del parámetro de regularización, por tanto tiene un efecto contrario al habitual. Si la regularización toma un valor bajo (cercano a cero) significa que el aporte de los estimadores en la predicción será alto (la penalización es baja) y si el parámetro toma un valor alto ocurre lo contrario (penalización alta). Entonces, con la regularización adecuada se busca reducir el efecto de overfitting en el modelo predictivo, al reducir o disminuir la participación de los estimadores en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.734102\n",
      "Test Accuracy LOGISTIC: 0.671827\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.68      0.68      1803\n",
      "          -       0.67      0.66      0.67      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.879572\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.731495\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720799\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.723129\n",
      "Test Accuracy LOGISTIC: 0.654095\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.72      0.68      1803\n",
      "          -       0.67      0.58      0.62      1751\n",
      "\n",
      "avg / total       0.66      0.65      0.65      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.814856\n",
      "Test Accuracy LOGISTIC: 0.689840\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.977209\n",
      "Test Accuracy LOGISTIC: 0.668731\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.67      0.67      1803\n",
      "          -       0.66      0.67      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.991277\n",
      "Test Accuracy LOGISTIC: 0.656065\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.66      0.66      0.66      1803\n",
      "          -       0.65      0.65      0.65      1751\n",
      "\n",
      "avg / total       0.66      0.66      0.66      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.994373\n",
      "Test Accuracy LOGISTIC: 0.646777\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.65      0.65      1803\n",
      "          -       0.64      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las métricas relacionadas al aplicar un modelo de Regresión Logística Regularizado, penalizando con\n",
    "normal $l_{2}$ y parámetro de regularización C = 0,1, para los diferentes casos solicitados.\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.892234   |         0.879572               |  0.814856                   \n",
    "  Test accuracy     | 0.719111   |         0.718548               |  0.689840              \n",
    "  Precision         | 0.72       |         0.72                   |  0.73             \n",
    "  Recall            | 0.72       |         0.72                   |  0.73             \n",
    "  F1-score          | 0.72       |         0.72                   |  0.73             \n",
    "  \n",
    "Como se puede apreciar, la conclusión es la misma que se realizó en las preguntas f) y g) debida a las mismas razones planteadas en tales preguntas, es decir, nuevamente se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un resultado mejor. Al eliminar la técnica de stopwords el efecto que produce es que el procesamiento se vuelve más lento, debido al aumento en el vocabulario, pero aún así se obtienen buenos resultados. No obstante, las palabras más frecuentes son en su mayoría artículos, pronombres y preposiciones perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Máquina de Vectores de Soporte (SVM) Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.808385\n",
      "Test Accuracy SVM: 0.688432\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.921497\n",
      "Test Accuracy SVM: 0.698283\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.70      0.70      0.70      1803\n",
      "          -       0.69      0.70      0.69      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.991559\n",
      "Test Accuracy SVM: 0.650155\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.66      0.66      1803\n",
      "          -       0.65      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.990433\n",
      "Test Accuracy SVM: 0.638052\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.65      0.64      1803\n",
      "          -       0.63      0.63      0.63      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.987338\n",
      "Test Accuracy SVM: 0.638615\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.65      0.65      1803\n",
      "          -       0.64      0.63      0.63      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las métricas relacionadas al aplicar SVM lineal, con un parámetro de regularización de C = 0,1,\n",
    "para los diferentes casos solicitados.\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.989589   |         0.987901               |  0.921497                   \n",
    "  Test accuracy     | 0.723614   |         0.738249               |  0.698283              \n",
    "  Precision         | 0.72       |         0.74                   |  0.70             \n",
    "  Recall            | 0.72       |         0.74                   |  0.70             \n",
    "  F1-score          | 0.72       |         0.74                   |  0.70             \n",
    "  \n",
    "Nuevamente se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un resultado mejor. Al eliminar la técnica de stopwords el procesamiento se produce un efecto más lento en su ejecución, debido al aumento en el vocabulario pero, el resultado mejora un poco debido a este aumento de información. Sin embargo, las palabras más frecuentes son en su mayoría artículos, pronombres y preposiciones perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### j) Comparando resultados métodos de clasificación\n",
    "\n",
    "Se comparan los diferentes métodos de clasificación vistos de acuerdo a las métricas: accuracy, precisión, recall\n",
    "y f1-score, con las técnicas de *lematización* y *stemming*. Para esto se construye un gráfico de barras que permita hacer dicha comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njXBQYWZmZo1wUGFmZmaN+P9IZdnfABfqYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d0ac1ab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d0aa123d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Lematización\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "\n",
    "#Guarda las metricas correspondientes en cada método\n",
    "accuracy_train.append(dict_bernoulli_binario[0])\n",
    "accuracy_train.append(dict_multinomial[0])\n",
    "accuracy_train.append(dict_log[0])\n",
    "accuracy_train.append(dict_svm[0])\n",
    "\n",
    "accuracy_test.append(dict_bernoulli_binario[1])\n",
    "accuracy_test.append(dict_multinomial[1])\n",
    "accuracy_test.append(dict_log[1])\n",
    "accuracy_test.append(dict_svm[1])\n",
    "\n",
    "precision.append(dict_bernoulli_binario[2])\n",
    "precision.append(dict_multinomial[2])\n",
    "precision.append(dict_log[2])\n",
    "precision.append(dict_svm[2])\n",
    "\n",
    "recall.append(dict_bernoulli_binario[3])\n",
    "recall.append(dict_multinomial[3])\n",
    "recall.append(dict_log[3])\n",
    "recall.append(dict_svm[3])\n",
    "\n",
    "fscore.append(dict_bernoulli_binario[4])\n",
    "fscore.append(dict_multinomial[4])\n",
    "fscore.append(dict_log[4])\n",
    "fscore.append(dict_svm[4])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(4)\n",
    "bar_width = 0.15\n",
    "opacity = 0.9\n",
    " \n",
    "rects1 = plt.bar(index, accuracy_train, bar_width,alpha=opacity,color='b',label='Accuracy Train')\n",
    "rects2 = plt.bar(index + bar_width, accuracy_test, bar_width,alpha=opacity,color='g',label='Accuracy Test')\n",
    "rects3 = plt.bar(index + 2*bar_width, precision, bar_width,alpha=opacity,color='r',label='Precision')\n",
    "rects4 = plt.bar(index + 3*bar_width, recall, bar_width,alpha=opacity,color='c',label='Recall')\n",
    "rects5 = plt.bar(index + 4*bar_width, fscore, bar_width,alpha=opacity,color='m',label='F1-Score')\n",
    "plt.xlabel('Metodos de Clasificacion')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Metricas con Lematizacion')\n",
    "plt.xticks(index + bar_width, ('BernoulliNB', 'MultinomialNB', 'LogisticRegression', 'LinearSVC'))\n",
    "plt.legend()\n",
    "\n",
    "#Stemming\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "\n",
    "#Guarda las metricas correspondientes en cada método\n",
    "accuracy_train.append(dict_bernoulli_binario[10])\n",
    "accuracy_train.append(dict_multinomial[10])\n",
    "accuracy_train.append(dict_log[10])\n",
    "accuracy_train.append(dict_svm[10])\n",
    "\n",
    "accuracy_test.append(dict_bernoulli_binario[11])\n",
    "accuracy_test.append(dict_multinomial[11])\n",
    "accuracy_test.append(dict_log[11])\n",
    "accuracy_test.append(dict_svm[11])\n",
    "\n",
    "precision.append(dict_bernoulli_binario[12])\n",
    "precision.append(dict_multinomial[12])\n",
    "precision.append(dict_log[12])\n",
    "precision.append(dict_svm[12])\n",
    "\n",
    "recall.append(dict_bernoulli_binario[13])\n",
    "recall.append(dict_multinomial[13])\n",
    "recall.append(dict_log[13])\n",
    "recall.append(dict_svm[13])\n",
    "\n",
    "fscore.append(dict_bernoulli_binario[14])\n",
    "fscore.append(dict_multinomial[14])\n",
    "fscore.append(dict_log[14])\n",
    "fscore.append(dict_svm[14])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(4)\n",
    "bar_width = 0.15\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, accuracy_train, bar_width,alpha=opacity,color='b',label='Accuracy Train')\n",
    "rects2 = plt.bar(index + bar_width, accuracy_test, bar_width,alpha=opacity,color='g',label='Accuracy Test')\n",
    "rects3 = plt.bar(index + 2*bar_width, precision, bar_width,alpha=opacity,color='r',label='Precision')\n",
    "rects4 = plt.bar(index + 3*bar_width, recall, bar_width,alpha=opacity,color='c',label='Recall')\n",
    "rects5 = plt.bar(index + 4*bar_width, fscore, bar_width,alpha=opacity,color='m',label='F1-Score')\n",
    " \n",
    "plt.xlabel('Metodos de Clasificacion')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Metricas con Stemming')\n",
    "plt.xticks(index + bar_width, ('BernoulliNB', 'MultinomialNB', 'LogisticRegression', 'LinearSVC'))\n",
    "plt.legend()\n",
    "\n",
    "#mostrar gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En ambos gráficos se puede observar que los cuatro métodos tienen un comportamiento similar obteniendo buenos resultados (*accuracy*, *precisión*, *recall* y *f1-score* > 70). Se puede observar que el método que obtiene mejores resultados es el *clasificador Bayesiano Ingenuo Multinomial*. No obstante, para el modelo de *Regresión logística* y *SVM lineal* no se realizo un estudio exhaustivo del parámetro de regulación a utilizar, por lo que con un regularizador más adecuado podría mejorar sus resultados, aún cuando éstos ya son buenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
