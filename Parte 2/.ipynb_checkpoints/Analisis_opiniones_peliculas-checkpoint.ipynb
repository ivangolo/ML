{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Construcción del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el conjunto de entrenamiento como el de pruebas, poseen 3554 registros para cada clase. Dichas clases se llaman \"Sentiment\" y \"Text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Función word_extractor\n",
    "\n",
    "La función word_extractor utiliza stemming para la extracción de trozos de textos de una frase. El stemming es un proceso heurístico que corta la derivación de las palabras para encontrar la raíz. Por ejemplo autómata, automático, automatizado se reducen a autómata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def word_extractor(text, stemming=True):\n",
    "    if stemming is True:\n",
    "        wordstemmer = PorterStemmer()\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ wordstemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "    else:\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "        \n",
    "#Con stemming\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se presenta es la extracción de trozos de texto en una frase. Al usar stemming para dicha tarea se puede apreciar en el output que se muestra la tarea en presente simple, lo que muestra que el stemming usa un vocabulario reducido al ignorar palabras como \"eating\" y \"loved\", ya que éstas no corresponden al presente simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#Sin stemming\n",
    "print word_extractor(\"I love to eat cake\", stemming=False)\n",
    "print word_extractor(\"I love eating cake\", stemming=False)\n",
    "print word_extractor(\"I loved eating the cake\", stemming=False)\n",
    "print word_extractor(\"I do not love eating cake\", stemming=False)\n",
    "print word_extractor(\"I don't love eating cake\", stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se ejecutó word_extractor sin usar stemming y se puede apreciar que muestra las palabras exactas, lo que se puede concluir que sin usar stemming se obtiene resultados mejores que con stemming debido a que no se redujo el vocabulario sin el uso de stemming.\n",
    "\n",
    "En resumen, si se consideran los textos “I love eating cake” y “I loved eating the cake”, con stemming se consigue “love eat cake” para ambos casos, mientras que sin stemming se obtiene “love eating cake” y “loved eating cake”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c) Función word_extractor2\n",
    "\n",
    "La función word_extractor2 utiliza el lematizador para extraer trozos de texto de una frase. La lematización es bastante similar al stemming, en el sentido que reducen las formas infleccionales de las palabras a una base común o raíz. Pero en el caso de la lematización y a partir de la implementación de *nltk*, se hace un chequeo de la forma reducida en el corpus de *WordNet*. Si no está en este último, se regresa la palabra original. En consecuencia, la lematización es un proceso más complejo que el stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#la variavle stopwords indica si el lematizador usa stopwords.\n",
    "def word_extractor2(text, stopWords=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    if stopWords is True:\n",
    "        commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "                  for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if stopWords is True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado, a diferencia de la función word_extractor que usaba stemming para poder extraer trozos de palabras de una frase, la función word_extractor2 que usa lematización para dicho objetivo devuelve cada trozo de palabra exacta, lo que permite un uso de vocabulario más amplio que usando stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d) CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#Conjunto de entrenamiento\n",
    "tags_train = []\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_train.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Conjunto de pruebas\n",
    "tags_test = []\n",
    "dist=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_test.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código que contiene el CountVectorizer tiene como objetivo guardar la cantidad de veces que aparece cierta palabra/número en el conjunto de entrenamiento/prueba. Las palabras más frecuentes en el conjunto de entrenamiento/pruebas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de entrenaiento:\n",
      "\n",
      "1) film (566)\n",
      "2) movie (481)\n",
      "3) one (246)\n",
      "4) like (245)\n",
      "5) ha (224)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_train.sort()\n",
    "tags_train[:] = tags_train[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de entrenaiento:\\n\"\n",
    "for i in range(0,10):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_train[i][1], tags_train[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de prueba:\n",
      "\n",
      "1) film (558)\n",
      "2) movie (540)\n",
      "3) one (250)\n",
      "4) ha (238)\n",
      "5) like (230)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_test.sort()\n",
    "tags_test[:] = tags_test[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de prueba:\\n\"\n",
    "for i in range(0,10):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_test[i][1], tags_test[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Desempeño de un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "dict_bernoulli_binario = []\n",
    "dict_multinomial = []\n",
    "dict_log = []\n",
    "dict_svm = []\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))\n",
    "    \n",
    "    #guarda las métricas de cada método para construir gráficos comparativos más adelante.\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(yt, model.predict(xt))\n",
    "    \n",
    "    if text == 'BernoulliNB':\n",
    "        dict_bernoulli_binario.append(acc_tr)\n",
    "        dict_bernoulli_binario.append(acc_test)\n",
    "        dict_bernoulli_binario.append(np.mean(precision))\n",
    "        dict_bernoulli_binario.append(np.mean(recall))\n",
    "        dict_bernoulli_binario.append(np.mean(fscore))\n",
    "    elif text == 'MULTINOMIAL':\n",
    "        dict_multinomial.append(acc_tr)\n",
    "        dict_multinomial.append(acc_test)\n",
    "        dict_multinomial.append(np.mean(precision))\n",
    "        dict_multinomial.append(np.mean(recall))\n",
    "        dict_multinomial.append(np.mean(fscore))\n",
    "    elif text == 'LOGISTIC':\n",
    "        dict_log.append(acc_tr)\n",
    "        dict_log.append(acc_test)\n",
    "        dict_log.append(np.mean(precision))\n",
    "        dict_log.append(np.mean(recall))\n",
    "        dict_log.append(np.mean(fscore))\n",
    "    elif text == 'SVM':\n",
    "        dict_svm.append(acc_tr)\n",
    "        dict_svm.append(acc_test)\n",
    "        dict_svm.append(np.mean(precision))\n",
    "        dict_svm.append(np.mean(recall))\n",
    "        dict_svm.append(np.mean(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas que calcula el método classification_report son las siguientes: precision, recall y F1-score, tal y como se muestra en el output generado usando el clasificador Bayesiano Ingenuo/Multinomial.\n",
    "\n",
    "- Precision es la cantidad de resultados positivos correctos divididos por la cantidad total de resultados positivos\n",
    "- Recall corresponde a la cantidad de resultados positivos correctos dividido por el número de resultados positivos que se debería obtener.\n",
    "- El F1-score es el promedio ponderado de recall y precision. La mejor puntuación corresponde a 1 y la peor corresponde a 0. La fórmula para calcular el F1-score es el siguiente:\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Clasificador Bayesiano Ingenuo (Binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.8270191  0.1729809] feels too formulaic and too familiar to produce the transgressive thrills of early underground work .\n",
      "\n",
      "[ 0.14234167  0.85765833] sweet and memorable film .\n",
      "\n",
      "[ 0.45497377  0.54502623] a mildly enjoyable if toothless adaptation of a much better book .\n",
      "\n",
      "[ 0.81860464  0.18139536] a remarkable movie with an unsatisfying ending , which is just the point .\n",
      "\n",
      "[  4.44889383e-05   9.99955511e-01] by turns gripping , amusing , tender and heart-wrenching , laissez-passer has all the earmarks of french cinema at its best .\n",
      "\n",
      "[ 0.4218986  0.5781014] even a hardened voyeur would require the patience of job to get through this interminable , shapeless documentary about the swinging subculture .\n",
      "\n",
      "[ 0.70867579  0.29132421] both damning and damned compelling .\n",
      "\n",
      "[ 0.14241358  0.85758642] priggish , lethargically paced parable of renewal .\n",
      "\n",
      "[ 0.74737361  0.25262639] needs more impressionistic cinematography and exhilarating point-of-view shots and fewer slow-motion 'grandeur' shots and quick-cut edits that often detract from the athleticism .\n",
      "\n",
      "[ 0.74511623  0.25488377] 'the ch�teau is never quite able to overcome the cultural moat surrounding its ludicrous and contrived plot . '\n",
      "\n",
      "[ 0.97726835  0.02273165] we never feel anything for these characters , and as a result the film is basically just a curiosity .\n",
      "\n",
      "[ 0.91942389  0.08057611] i got a headache watching this meaningless downer .\n",
      "\n",
      "[ 0.9434098  0.0565902] director yu seems far more interested in gross-out humor than in showing us well-thought stunts or a car chase that we haven't seen 10 , 000 times .\n",
      "\n",
      "[ 0.6526231  0.3473769] the movie plays up the cartoon's more obvious strength of snazziness while neglecting its less conspicuous writing strength .\n",
      "\n",
      "[ 0.35302148  0.64697852] it's a lovely film with lovely performances by buy and accorsi .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[  5.41951967e-04   9.99458048e-01] exquisitely nuanced in mood tics and dialogue , this chamber drama is superbly acted by the deeply appealing veteran bouquet and the chilling but quite human berling .\n",
      "\n",
      "[ 0.0037887  0.9962113] mike white's deft combination of serious subject matter and dark , funny humor make \" \" the good girl \" a film worth watching .\n",
      "\n",
      "[ 0.0880277  0.9119723] [hayek] throws herself into this dream hispanic role with a teeth-clenching gusto , she strikes a potent chemistry with molina and she gradually makes us believe she is kahlo .\n",
      "\n",
      "[ 0.04008395  0.95991605] greg kinnear gives a mesmerizing performance as a full-fledged sex addict who is in complete denial about his obsessive behavior .\n",
      "\n",
      "[ 0.55326195  0.44673805] a thriller without a lot of thrills .\n",
      "\n",
      "[ 0.18414309  0.81585691] the niftiest trick perpetrated by the importance of being earnest is the alchemical transmogrification of wilde into austen--and a hollywood-ized austen at that .\n",
      "\n",
      "[ 0.98763187  0.01236813] whatever complaints i might have , i'd take [its] earnest errors and hard-won rewards over the bombastic self-glorification of other feel-good fiascos like antwone fisher or the emperor's club any time .\n",
      "\n",
      "[ 0.38145486  0.61854514] makes even the claustrophobic on-board quarters seem fun .\n",
      "\n",
      "[ 0.47889111  0.52110889] some of it is clever , but it is never melodic/\n",
      "\n",
      "[ 0.3179203  0.6820797] both the crime story and the love story are unusual . but they don't fit well together and neither is well told .\n",
      "\n",
      "[ 0.97910619  0.02089381] has enough gun battles and throwaway humor to cover up the yawning chasm where the plot should be .\n",
      "\n",
      "[ 0.51937642  0.48062358] the central character isn't complex enough to hold our interest .\n",
      "\n",
      "[  2.52820253e-05   9.99974718e-01] this odd , poetic road movie , spiked by jolts of pop music , pretty much takes place in morton's ever-watchful gaze -- and it's a tribute to the actress , and to her inventive director , that the journey is such a mesmerizing one .\n",
      "\n",
      "[ 0.9332927  0.0667073] try as i may , i can't think of a single good reason to see this movie , even though everyone in my group extemporaneously shouted , 'thank you ! ' when leguizamo finally plugged an irritating character late in the movie .\n",
      "\n",
      "[ 0.99531838  0.00468162] benigni's pinocchio is extremely straight and mind-numbingly stilted , its episodic pacing keeping the film from developing any storytelling flow .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.878728\n",
      "Test Accuracy BernoulliNB: 0.701098\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.68      0.70      1803\n",
      "          -       0.69      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "[  6.26205067e-04   9.99373795e-01] by turns gripping , amusing , tender and heart-wrenching , laissez-passer has all the earmarks of french cinema at its best .\n",
      "\n",
      "[ 0.89983058  0.10016942] though howard demonstrates a great eye as a director , this southern gothic drama is sadly a tough sit , with an undeveloped narrative and enough flashbacks and heavy-handed metaphors to choke a horse -- or at least slow him down to a canter .\n",
      "\n",
      "[ 0.37870087  0.62129913] the innocence of holiday cheer ain't what it used to be .\n",
      "\n",
      "[ 0.78149673  0.21850327] has all the poignancy of a hallmark card and all the comedy of a gallagher stand-up act .\n",
      "\n",
      "[ 0.9333226  0.0666774] return to never land may be another shameless attempt by disney to rake in dough from baby boomer families , but it's not half-bad .\n",
      "\n",
      "[ 0.67281176  0.32718824] no aspirations to social import inform the movie version . this is a shameless sham , calculated to cash in on the popularity of its stars .\n",
      "\n",
      "[ 0.02344087  0.97655913] this charming but slight tale has warmth , wit and interesting characters compassionately portrayed .\n",
      "\n",
      "[ 0.08875756  0.91124244] there's something unintentionally comic in the film's drumbeat about authenticity , given the stale plot and pornographic way the film revels in swank apartments , clothes and parties .\n",
      "\n",
      "[ 0.71150862  0.28849138] if this is satire , it's the smug and self-congratulatory kind that lets the audience completely off the hook .\n",
      "\n",
      "[ 0.82370187  0.17629813] shrewd but pointless .\n",
      "\n",
      "[ 0.07293083  0.92706917] macdowell . . . gives give a solid , anguished performance that eclipses nearly everything else she's ever done .\n",
      "\n",
      "[ 0.19825405  0.80174595] one of those rare films that come by once in a while with flawless amounts of acting , direction , story and pace .\n",
      "\n",
      "[ 0.75544041  0.24455959] a sequel that's much too big for its britches .\n",
      "\n",
      "[ 0.35920703  0.64079297] tambor and clayburgh make an appealing couple � he's understated and sardonic , she's appealingly manic and energetic . both deserve better .\n",
      "\n",
      "[ 0.03694216  0.96305784] despite the predictable parent vs . child coming-of-age theme , first-class , natural acting and a look at \" the real americans \" make this a charmer .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resumen, al usar el Clasificador Bayesiano Ingenuo Binario, se obtuvieron los siguientes resultados:\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.958638   |         0.955262               |  0.878728                   \n",
    "  Test accuracy     | 0.738531   |         0.748663               |  0.701098              \n",
    "  Precision         | 0.74       |         0.75                   |  0.70             \n",
    "  Recall            | 0.74       |         0.75                   |  0.70             \n",
    "  F1-score          | 0.74       |         0.75                   |  0.70             \n",
    "  \n",
    "En términos generales, se obtienen buenos resultados utilizando lematización y stemming, siendo este último un poco mejor. Al trabajar sin stopwords el procesamiento se vuelve más lento al aumentar el vocabulario pero a pesar de eso, se obtienen buenos resultados. Sin embargo, las palabras más frecuentes son artículos, pronombres y preposiciones en su mayoría, lo que causa la pérdida del poder de análisis en los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Clasificador Bayesiano Ingenuo Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.00842009  0.99157991] a gorgeous , high-spirited musical from india that exquisitely blends music , dance , song , and high drama .\n",
      "\n",
      "[ 0.9824049  0.0175951] the french director has turned out nearly 21/2 hours of unfocused , excruciatingly tedious cinema that , half an hour in , starts making water torture seem appealing .\n",
      "\n",
      "[ 0.12202296  0.87797704] it gives devastating testimony to both people's capacity for evil and their heroic capacity for good .\n",
      "\n",
      "[ 0.01475931  0.98524069] payne constructs a hilarious ode to middle america and middle age with this unlikely odyssey , featuring a pathetic , endearing hero who is all too human .\n",
      "\n",
      "[ 0.4461235  0.5538765] the screenplay by james eric , james horton and director peter o'fallon . . . is so pat it makes your teeth hurt .\n",
      "\n",
      "[ 0.95755788  0.04244212] earnest but heavy-handed .\n",
      "\n",
      "[ 0.00107184  0.99892816] those who would follow haneke on his creepy explorations . . . are rewarded by brutal , committed performances from huppert and magimel .\n",
      "\n",
      "[ 0.91268863  0.08731137] i can't say that i liked homeboy ; it'd be more accurate to say that i found it intriguing , bizarre , dogma-like in spots - and quite truthful , in its way .\n",
      "\n",
      "[ 0.97851174  0.02148826] unintelligible , poorly acted , brain-slappingly bad , harvard man is ludicrous enough that it could become a cult classic .\n",
      "\n",
      "[ 0.22209369  0.77790631] handled correctly , wilde's play is a masterpiece of elegant wit and artifice . here , alas , it collapses like an overcooked souffl� .\n",
      "\n",
      "[ 0.87128457  0.12871543] that the e-graveyard holds as many good ideas as bad is the cold comfort that chin's film serves up with style and empathy .\n",
      "\n",
      "[ 0.76482206  0.23517794] a manipulative feminist empowerment tale thinly posing as a serious drama about spousal abuse .\n",
      "\n",
      "[ 0.90107134  0.09892866] if you are curious to see the darker side of what's going on with young tv actors ( dawson leery did what ? ! ? ) , or see some interesting storytelling devices , you might want to check it out , but there's nothing very attractive about this movie .\n",
      "\n",
      "[ 0.0485262  0.9514738] it's sweet , funny , charming , and completely delightful .\n",
      "\n",
      "[  4.56785455e-04   9.99543215e-01] a film centering on a traditional indian wedding in contemporary new delhi may not sound like specialized fare , but mira nair's film is an absolute delight for all audiences .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.14349132  0.85650868] curling may be a unique sport but men with brooms is distinctly ordinary .\n",
      "\n",
      "[ 0.44646432  0.55353568] who needs love like this ?\n",
      "\n",
      "[ 0.88944918  0.11055082] a jumbled fantasy comedy that did not figure out a coherent game plan at scripting , shooting or post-production stages .\n",
      "\n",
      "[ 0.72483618  0.27516382] . . . if you're in a mind set for goofy comedy , the troopers will entertain with their gross outs , bawdy comedy and head games .\n",
      "\n",
      "[ 0.6552664  0.3447336] i'd be hard pressed to think of a film more cloyingly sappy than evelyn this year .\n",
      "\n",
      "[ 0.38870493  0.61129507] god is great , the movie's not .\n",
      "\n",
      "[ 0.58285807  0.41714193] broomfield is energized by volletta wallace's maternal fury , her fearlessness , and because of that , his film crackles .\n",
      "\n",
      "[ 0.46958764  0.53041236] the movie's downfall is to substitute plot for personality . it doesn't really know or care about the characters , and uses them as markers for a series of preordained events .\n",
      "\n",
      "[  3.38054178e-05   9.99966195e-01] by turns gripping , amusing , tender and heart-wrenching , laissez-passer has all the earmarks of french cinema at its best .\n",
      "\n",
      "[ 0.09120847  0.90879153] speaks eloquently about the symbiotic relationship between art and life .\n",
      "\n",
      "[  9.99917123e-01   8.28770497e-05] halfway through , however , having sucked dry the undead action flick formula , blade ii mutates into a gross-out monster movie with effects that are more silly than scary .\n",
      "\n",
      "[ 0.85731142  0.14268858] just about the best straight-up , old-school horror film of the last 15 years .\n",
      "\n",
      "[ 0.22138782  0.77861218] go for la salle's performance , and make do as best you can with a stuttering script .\n",
      "\n",
      "[ 0.06188819  0.93811181] the best way to hope for any chance of enjoying this film is by lowering your expectations . then lower them a bit more .\n",
      "\n",
      "[  5.90666763e-05   9.99940933e-01] the spaniel-eyed jean reno infuses hubert with a mixture of deadpan cool , wry humor and just the measure of tenderness required to give this comic slugfest some heart .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.882949\n",
      "Test Accuracy MULTINOMIAL: 0.705319\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.70      0.71      1803\n",
      "          -       0.70      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "[ 0.94832558  0.05167442] unspeakable , of course , barely begins to describe the plot and its complications . vulgar is too optimistic a title .\n",
      "\n",
      "[ 0.69688273  0.30311727] i suspect that there are more interesting ways of dealing with the subject .\n",
      "\n",
      "[ 0.61907455  0.38092545] manages to be original , even though it rips off many of its ideas .\n",
      "\n",
      "[ 0.16157907  0.83842093] johnson has , in his first film , set himself a task he is not nearly up to .\n",
      "\n",
      "[ 0.5784384  0.4215616] [cho's face is] an amazing slapstick instrument , creating a scrapbook of living mug shots .\n",
      "\n",
      "[ 0.82102264  0.17897736] john carlen's script is full of unhappy , two-dimensional characters who are anything but compelling .\n",
      "\n",
      "[ 0.70536327  0.29463673] what madonna does here can't properly be called acting -- more accurately , it's moving and it's talking and it's occasionally gesturing , sometimes all at once .\n",
      "\n",
      "[ 0.95306302  0.04693698] i can't say that i liked homeboy ; it'd be more accurate to say that i found it intriguing , bizarre , dogma-like in spots - and quite truthful , in its way .\n",
      "\n",
      "[ 0.64719253  0.35280747] the result puts a human face on derrida , and makes one of the great minds of our times interesting and accessible to people who normally couldn't care less .\n",
      "\n",
      "[ 0.18518031  0.81481969] otto-sallies has a real filmmaker's eye .\n",
      "\n",
      "[ 0.30166183  0.69833817] a great cast and a wonderful but sometimes confusing flashback movie about growing up in a dysfunctional family .\n",
      "\n",
      "[ 0.04284267  0.95715733] as relationships shift , director robert j . siegel allows the characters to inhabit their world without cleaving to a narrative arc .\n",
      "\n",
      "[ 0.85660968  0.14339032] run , don't walk , to see this barbed and bracing comedy on the big screen .\n",
      "\n",
      "[ 0.93042489  0.06957511] the attempt is courageous , even if the result is wildly uneven .\n",
      "\n",
      "[ 0.428765  0.571235] a work that lacks both a purpose and a strong pulse .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resumen, al usar el Clasificador Bayesiano Ingenuo Multinomial, se obtuvieron los siguientes resultados:\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.959482   |         0.955543               |  0.882949                   \n",
    "  Test accuracy     | 0.740782   |         0.747537               |  0.705319              \n",
    "  Precision         | 0.74       |         0.75                   |  0.71             \n",
    "  Recall            | 0.74       |         0.75                   |  0.71             \n",
    "  F1-score          | 0.74       |         0.75                   |  0.71             \n",
    "  \n",
    "La conclusión que se obtiene a partir de estos resultados es la misma que para el caso del ejercicio f), debida a las mismas razones planteadas anteriormente en dicho ejercicio, es decir, se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un mejor resultado. Al trabajar sin stopwords el efecto que produce es que el procesamiento se vuelve más lento, debido al aumento en el vocabulario pero aún así se obtienen buenos resultados. No obstante, las palabras más frecuentes son artículos, pronombres y preposiciones en su mayoría perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Regresión Logı́stica Regularizado\n",
    "\n",
    "La regularización permite controlar el efecto de los estimadores en la predicción, es decir, el aporte que tienen\n",
    "estos. Para el caso del algoritmo de Regresión logística (ocurre lo mismo en SVM lineal) utiliza como parámetro\n",
    "el valor inverso del parámetro de regularización, por tanto tiene un efecto contrario al habitual. Si la regularización toma un valor bajo (cercano a cero) significa que el aporte de los estimadores en la predicción será alto (la penalización es baja) y si el parámetro toma un valor alto ocurre lo contrario (penalización alta). Entonces, con la regularización adecuada se busca reducir el efecto de overfitting en el modelo predictivo, al reducir o disminuir la participación de los estimadores en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.734102\n",
      "Test Accuracy LOGISTIC: 0.671827\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.68      0.68      1803\n",
      "          -       0.67      0.66      0.67      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.879572\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.731495\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720799\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.723129\n",
      "Test Accuracy LOGISTIC: 0.654095\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.72      0.68      1803\n",
      "          -       0.67      0.58      0.62      1751\n",
      "\n",
      "avg / total       0.66      0.65      0.65      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.814856\n",
      "Test Accuracy LOGISTIC: 0.689840\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.977209\n",
      "Test Accuracy LOGISTIC: 0.668731\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.67      0.67      1803\n",
      "          -       0.66      0.67      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.991277\n",
      "Test Accuracy LOGISTIC: 0.656065\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.66      0.66      0.66      1803\n",
      "          -       0.65      0.65      0.65      1751\n",
      "\n",
      "avg / total       0.66      0.66      0.66      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.994373\n",
      "Test Accuracy LOGISTIC: 0.646777\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.65      0.65      1803\n",
      "          -       0.64      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las métricas relacionadas al aplicar un modelo de Regresión Logística Regularizado, penalizando con\n",
    "normal $l_{2}$ y parámetro de regularización C = 0,1, para los diferentes casos solicitados.\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.892234   |         0.879572               |  0.814856                   \n",
    "  Test accuracy     | 0.719111   |         0.718548               |  0.689840              \n",
    "  Precision         | 0.72       |         0.72                   |  0.73             \n",
    "  Recall            | 0.72       |         0.72                   |  0.73             \n",
    "  F1-score          | 0.72       |         0.72                   |  0.73             \n",
    "  \n",
    "Como se puede apreciar, la conclusión es la misma que se realizó en las preguntas f) y g) debida a las mismas razones planteadas en tales preguntas, es decir, nuevamente se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un resultado mejor. Al eliminar la técnica de stopwords el efecto que produce es que el procesamiento se vuelve más lento, debido al aumento en el vocabulario, pero aún así se obtienen buenos resultados. No obstante, las palabras más frecuentes son en su mayoría artículos, pronombres y preposiciones perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Máquina de Vectores de Soporte (SVM) Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.808385\n",
      "Test Accuracy SVM: 0.688432\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.921497\n",
      "Test Accuracy SVM: 0.698283\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.70      0.70      0.70      1803\n",
      "          -       0.69      0.70      0.69      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.991559\n",
      "Test Accuracy SVM: 0.650155\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.66      0.66      1803\n",
      "          -       0.65      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.990996\n",
      "Test Accuracy SVM: 0.640585\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.64      0.64      1803\n",
      "          -       0.63      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.982836\n",
      "Test Accuracy SVM: 0.638334\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.66      0.59      0.63      1803\n",
      "          -       0.62      0.68      0.65      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las métricas relacionadas al aplicar SVM lineal, con un parámetro de regularización de C = 0,1,\n",
    "para los diferentes casos solicitados.\n",
    "\n",
    "**Métrica**  | **Lematizador**   |  **Lematizador sin stopwords** | **Stemming**  \n",
    "  ----------------- | ---------- | -----------------------------  | ------------------  \n",
    "  Training accuracy | 0.989589   |         0.987901               |  0.921497                   \n",
    "  Test accuracy     | 0.723614   |         0.738249               |  0.698283              \n",
    "  Precision         | 0.72       |         0.74                   |  0.70             \n",
    "  Recall            | 0.72       |         0.74                   |  0.70             \n",
    "  F1-score          | 0.72       |         0.74                   |  0.70             \n",
    "  \n",
    "Nuevamente se obtienen buenos resultados utilizando lematización y stemming, siendo este último el que logra un resultado mejor. Al eliminar la técnica de stopwords el procesamiento se produce un efecto más lento en su ejecución, debido al aumento en el vocabulario pero, el resultado mejora un poco debido a este aumento de información. Sin embargo, las palabras más frecuentes son en su mayoría artículos, pronombres y preposiciones perdiendo poder de análisis en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### j) Comparando resultados métodos de clasificación\n",
    "\n",
    "Se comparan los diferentes métodos de clasificación vistos de acuerdo a las métricas: accuracy, precisión, recall\n",
    "y f1-score, con las técnicas de *lematización* y *stemming*. Para esto se construye un gráfico de barras que permita hacer dicha comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlZI/4fUlaBdnw5c14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f620a78cb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "\n",
    "#Guarda las metricas correspondientes en cada método\n",
    "accuracy_train.append(dict_bernoulli_binario[0])\n",
    "accuracy_train.append(dict_multinomial[0])\n",
    "accuracy_train.append(dict_log[0])\n",
    "accuracy_train.append(dict_svm[0])\n",
    "\n",
    "accuracy_test.append(dict_bernoulli_binario[1])\n",
    "accuracy_test.append(dict_multinomial[1])\n",
    "accuracy_test.append(dict_log[1])\n",
    "accuracy_test.append(dict_svm[1])\n",
    "\n",
    "precision.append(dict_bernoulli_binario[2])\n",
    "precision.append(dict_multinomial[2])\n",
    "precision.append(dict_log[2])\n",
    "precision.append(dict_svm[2])\n",
    "\n",
    "recall.append(dict_bernoulli_binario[3])\n",
    "recall.append(dict_multinomial[3])\n",
    "recall.append(dict_log[3])\n",
    "recall.append(dict_svm[3])\n",
    "\n",
    "fscore.append(dict_bernoulli_binario[4])\n",
    "fscore.append(dict_multinomial[4])\n",
    "fscore.append(dict_log[4])\n",
    "fscore.append(dict_svm[4])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(4)\n",
    "bar_width = 0.15\n",
    "opacity = 0.9\n",
    " \n",
    "rects1 = plt.bar(index, accuracy_train, bar_width,alpha=opacity,color='b',label='Accuracy Train')\n",
    "rects2 = plt.bar(index + bar_width, accuracy_test, bar_width,alpha=opacity,color='g',label='Accuracy Test')\n",
    "rects3 = plt.bar(index + 2*bar_width, precision, bar_width,alpha=opacity,color='r',label='Precision')\n",
    "rects4 = plt.bar(index + 3*bar_width, recall, bar_width,alpha=opacity,color='c',label='Recall')\n",
    "rects5 = plt.bar(index + 4*bar_width, fscore, bar_width,alpha=opacity,color='m',label='F1-Score')\n",
    "plt.xlabel('Metodos de Clasificacion')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Metricas')\n",
    "plt.xticks(index + bar_width, ('BernoulliNB', 'MultinomialNB', 'LogisticRegression', 'LinearSVC'))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
