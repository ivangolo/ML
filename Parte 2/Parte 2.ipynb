{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Construcción del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el conjunto de entrenamiento como el de pruebas, poseen 3554 registros para cada clase. Dichas clases se llaman \"Sentiment\" y \"Text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Función word_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def word_extractor(text, stemming=True):\n",
    "    if stemming is True:\n",
    "        wordstemmer = PorterStemmer()\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ wordstemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "    else:\n",
    "        commonwords = stopwords.words('english')\n",
    "        text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "        words = \"\"\n",
    "        wordtokens = [ word.lower() for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "        for word in wordtokens:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        return words\n",
    "        \n",
    "#Con stemming\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se presenta es la extracción de trozos de texto en una frase. Al usar stemming para dicha tarea se puede apreciar en el output que se muestra la tarea en presente simple, lo que muestra que el stemming usa un vocabulario reducido al ignorar palabras como \"eating\" y \"loved\", ya que éstas no corresponden al presente simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#Sin stemming\n",
    "print word_extractor(\"I love to eat cake\", stemming=False)\n",
    "print word_extractor(\"I love eating cake\", stemming=False)\n",
    "print word_extractor(\"I loved eating the cake\", stemming=False)\n",
    "print word_extractor(\"I do not love eating cake\", stemming=False)\n",
    "print word_extractor(\"I don't love eating cake\", stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se ejecutó word_extractor sin usar stemming y se puede apreciar que muestra las palabras exactas, lo que se puede concluir que sin usar stemming se obtiene resultados mejores que con stemming debido a que no se redujo el vocabulario sin el uso de stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c) Función word_extractor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "#la variavle stopwords indica si el lematizador usa stopwords.\n",
    "def word_extractor2(text, stopWords=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    if stopWords is True:\n",
    "        commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "                  for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if stopWords is True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de la función word_extractor, que usaba stemming para poder extraer trozos de palabras de una frase, la función word_extractor2 que usa lematización para dicho objetivo devuelve cada trozo de palabra exacta, lo que permite un uso de vocabulario más amplio que usando stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d) CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#Conjunto de entrenamiento\n",
    "tags_train = []\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_train.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Conjunto de pruebas\n",
    "tags_test = []\n",
    "dist=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "for tag, count in zip(vocab, dist):\n",
    "    tags_test.append((count, tag))\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código que contiene el CountVectorizer tiene como objetivo guardar la cantidad de veces que aparece cierta palabra/número en el conjunto de entrenamiento/prueba. Las palabras más frecuentes en el conjunto de entrenamiento/pruebas son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de entrenaiento:\n",
      "\n",
      "1) film (566)\n",
      "2) movie (481)\n",
      "3) one (246)\n",
      "4) like (245)\n",
      "5) ha (224)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_train.sort()\n",
    "tags_train[:] = tags_train[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de entrenaiento:\\n\"\n",
    "for i in range(0,5):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_train[i][1], tags_train[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes del conjunto de prueba:\n",
      "\n",
      "1) film (558)\n",
      "2) movie (540)\n",
      "3) one (250)\n",
      "4) ha (238)\n",
      "5) like (230)\n"
     ]
    }
   ],
   "source": [
    "#Top 10 palabras más frecuentes conjunto de entrenamiento\n",
    "tags_test.sort()\n",
    "tags_test[:] = tags_test[::-1]\n",
    "\n",
    "print \"Palabras más frecuentes del conjunto de prueba:\\n\"\n",
    "for i in range(0,5):\n",
    "    print str(i+1)+\") %s (%d)\"%(tags_test[i][1], tags_test[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Desempeño de un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas que calcula el método classification_report son las siguientes: precision, recall y F1-score, tal y como se muestra en el output generado usando el clasificador Bayesiano Ingenuo/Multinomial.\n",
    "\n",
    "- Precision es la cantidad de resultados positivos correctos divididos por la cantidad total de resultados positivos\n",
    "- Recall corresponde a la cantidad de resultados positivos correctos dividido por el número de resultados positivos que se debería obtener.\n",
    "- El F1-score es el promedio ponderado de recall y precision. La mejor puntuación corresponde a 1 y la peor corresponde a 0. La fórmula para calcular el F1-score es el siguiente:\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Clasificador Bayesiano Ingenuo (Binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.01685004  0.98314996] god help the poor woman if attal is this insecure in real life : his fictional yvan's neuroses are aggravating enough to exhaust the patience of even the most understanding spouse .\n",
      "\n",
      "[ 0.74278439  0.25721561] those 24-and-unders looking for their own caddyshack to adopt as a generational signpost may have to keep on looking .\n",
      "\n",
      "[ 0.74010191  0.25989809] melodrama with a message .\n",
      "\n",
      "[ 0.99700411  0.00299589] there is an almost poignant dimension to the way that every major stunt seagal's character . . . performs is shot from behind , as if it could fool us into thinking that we're not watching a double .\n",
      "\n",
      "[ 0.38605591  0.61394409] this may be dover kosashvili's feature directing debut , but it looks an awful lot like life -- gritty , awkward and ironic .\n",
      "\n",
      "[ 0.76205032  0.23794968] far from heaven is a dazzling conceptual feat , but more than that , it's a work of enthralling drama .\n",
      "\n",
      "[ 0.06533859  0.93466141] sheridan seems terrified of the book's irreverent energy , and scotches most of its �lan , humor , bile , and irony .\n",
      "\n",
      "[ 0.69883913  0.30116087] a well made indieflick in need of some trims and a more chemistry between its stars .\n",
      "\n",
      "[ 0.84284985  0.15715015] \" 13 conversations \" holds its goodwill close , but is relatively slow to come to the point .\n",
      "\n",
      "[ 0.20002558  0.79997442] \" what john does is heroic , but we don't condone it , \" one of the film's stars recently said , a tortuous comment that perfectly illustrates the picture's moral schizophrenia .\n",
      "\n",
      "[ 0.0011767  0.9988233] a different kind of love story - one that is dark , disturbing , painful to watch , yet compelling .\n",
      "\n",
      "[ 0.98121434  0.01878566] the movie's plot is almost entirely witless and inane , carrying every gag two or three times beyond its limit to sustain a laugh .\n",
      "\n",
      "[ 0.23600058  0.76399942] a sharp satire of desperation and cinematic deception .\n",
      "\n",
      "[ 0.89411332  0.10588668] i simply can't recommend it enough .\n",
      "\n",
      "[ 0.98743055  0.01256945] shatner is probably the funniest person in the film , which gives you an idea just how bad it was .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.93974526  0.06025474] the sweetest thing leaves a bitter taste .\n",
      "\n",
      "[ 0.17674497  0.82325503] more a load of enjoyable , conan-esque claptrap than the punishing , special-effects soul assaults the mummy pictures represent .\n",
      "\n",
      "[ 0.88266112  0.11733888] instead of hiding pinocchio from critics , miramax should have hidden it from everyone .\n",
      "\n",
      "[ 0.03847473  0.96152527] what might have been a predictably heartwarming tale is suffused with complexity .\n",
      "\n",
      "[ 0.05373896  0.94626104] \" spider-man is better than any summer blockbuster we had to endure last summer , and hopefully , sets the tone for a summer of good stuff . if you're a comic fan , you can't miss it . if you're not , you'll still have a good time . \"\n",
      "\n",
      "[ 0.7709792  0.2290208] proof once again that if the filmmakers just follow the books , they can't go wrong . better effects , better acting and a hilarious kenneth branagh . an excellent sequel .\n",
      "\n",
      "[ 0.47537219  0.52462781] . . . the kind of movie you see because the theater has air conditioning .\n",
      "\n",
      "[ 0.39962138  0.60037862] there's a delightfully quirky movie to be made from curling , but brooms isn't it .\n",
      "\n",
      "[  9.99509737e-01   4.90262788e-04] most new movies have a bright sheen . some , like ballistic , arrive stillborn . . . looking like the beaten , well-worn video box cover of seven years into the future .\n",
      "\n",
      "[ 0.03499712  0.96500288] films about loss , grief and recovery are pretty valuable these days . seen in that light , moonlight mile should strike a nerve in many .\n",
      "\n",
      "[ 0.74007253  0.25992747] it's clear that mehta simply wanted to update her beloved genre for the thousands of indians who fancy themselves too sophisticated for the cheese-laced spectacles that pack 'em in on the subcontinent .\n",
      "\n",
      "[ 0.02870729  0.97129271] altogether , this is successful as a film , while at the same time being a most touching reconsideration of the familiar masterpiece .\n",
      "\n",
      "[ 0.86363938  0.13636062] charming and funny ( but ultimately silly ) movie .\n",
      "\n",
      "[  9.99445712e-01   5.54287863e-04] myers never knows when to let a gag die ; thus , we're subjected to one mind-numbingly lengthy riff on poo and pee jokes after another .\n",
      "\n",
      "[ 0.93522931  0.06477069] it's better suited for the history or biography channel , but there's no arguing the tone of the movie - it leaves a bad taste in your mouth and questions on your mind .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.878728\n",
      "Test Accuracy BernoulliNB: 0.701098\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.68      0.70      1803\n",
      "          -       0.69      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "[ 0.59967244  0.40032756] possibly the most irresponsible picture ever released by a major film studio .\n",
      "\n",
      "[ 0.42926542  0.57073458] [fessenden] is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "\n",
      "[ 0.19825405  0.80174595] one of those rare films that come by once in a while with flawless amounts of acting , direction , story and pace .\n",
      "\n",
      "[ 0.48441011  0.51558989] it's not original enough .\n",
      "\n",
      "[ 0.37252962  0.62747038] a naturally funny film , home movie makes you crave chris smith's next movie .\n",
      "\n",
      "[ 0.59637639  0.40362361] interesting , but not compelling .\n",
      "\n",
      "[ 0.15885719  0.84114281] it offers little beyond the momentary joys of pretty and weightless intellectual entertainment .\n",
      "\n",
      "[ 0.13353964  0.86646036] argento , at only 26 , brings a youthful , out-to-change-the-world aggressiveness to the project , as if she's cut open a vein and bled the raw film stock .\n",
      "\n",
      "[ 0.68289256  0.31710744] if you're not a prepubescent girl , you'll be laughing at britney spears' movie-starring debut whenever it doesn't have you impatiently squinting at your watch .\n",
      "\n",
      "[ 0.80231313  0.19768687] the worst kind of independent ; the one where actors play dress down hicks and ponderously mope around trying to strike lightning as captured by their 1970s predecessors\n",
      "\n",
      "[ 0.17526069  0.82473931] otto-sallies has a real filmmaker's eye .\n",
      "\n",
      "[ 0.01450511  0.98549489] benefits from a strong performance from zhao , but it's dong jie's face you remember at the end .\n",
      "\n",
      "[ 0.04980854  0.95019146] skins has a right to yawp , and we have a right to our grains of salt .\n",
      "\n",
      "[ 0.73565062  0.26434938] sluggish , tonally uneven .\n",
      "\n",
      "[ 0.06610767  0.93389233] though the controversial korean filmmaker's latest effort is not for all tastes , it offers gorgeous imagery , effective performances , and an increasingly unsettling sense of foreboding .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los resultados obtenidos usando el Clasificador Bayesiano Ingenuo Binario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Clasificador Bayesiano Ingenuo Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.31177543  0.68822457] i still can't relate to stuart : he's a mouse , for cryin' out loud , and all he does is milk it with despondent eyes and whine that nobody treats him human enough .\n",
      "\n",
      "[ 0.7651984  0.2348016] a muddy psychological thriller rife with miscalculations . it makes me say the obvious : abandon all hope of a good movie ye who enter here .\n",
      "\n",
      "[ 0.88877297  0.11122703] �passable enough for a shoot-out in the o . k . court house of life type of flick . strictly middle of the road .\n",
      "\n",
      "[ 0.93182264  0.06817736] the fact that the 'best part' of the movie comes from a 60-second homage to one of demme's good films doesn't bode well for the rest of it .\n",
      "\n",
      "[ 0.01110711  0.98889289] if \" lilo & stitch \" isn't the most edgy piece of disney animation to hit the silver screen , then this first film to use a watercolor background since \" dumbo \" certainly ranks as the most original in years .\n",
      "\n",
      "[ 0.11895401  0.88104599] a solid examination of the male midlife crisis .\n",
      "\n",
      "[ 0.95628122  0.04371878] this rough trade punch-and-judy act didn't play well then and it plays worse now .\n",
      "\n",
      "[ 0.11697263  0.88302737] audrey tatou has a knack for picking roles that magnify her outrageous charm , and in this literate french comedy , she's as morning-glory exuberant as she was in am�lie .\n",
      "\n",
      "[ 0.76893919  0.23106081] one of those movies that catches you up in something bigger than yourself , namely , an archetypal desire to enjoy good trash every now and then .\n",
      "\n",
      "[ 0.28901348  0.71098652] interesting , but not compelling .\n",
      "\n",
      "[ 0.32845002  0.67154998] obstacles are too easily overcome and there isn't much in the way of character development in the script .\n",
      "\n",
      "[ 0.93179726  0.06820274] such a wildly uneven hit-and-miss enterprise , you can't help suspecting that it was improvised on a day-to-day basis during production .\n",
      "\n",
      "[ 0.81607293  0.18392707] ihops don't pile on this much syrup .\n",
      "\n",
      "[ 0.28007022  0.71992978] unlike his directorial efforts , la femme nikita and the professional , the transporter lacks besson's perspective as a storyteller .\n",
      "\n",
      "[ 0.75915381  0.24084619] a pleasant , if forgettable , romp of a film .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.96573087  0.03426913] this is a movie that starts out like heathers , then becomes bring it on , then becomes unwatchable .\n",
      "\n",
      "[ 0.97825858  0.02174142] consists of a plot and jokes done too often by people far more talented than ali g\n",
      "\n",
      "[ 0.96318404  0.03681596] an ambitious , serious film that manages to do virtually everything wrong ; sitting through it is something akin to an act of cinematic penance .\n",
      "\n",
      "[ 0.03591092  0.96408908] stripped almost entirely of such tools as nudity , profanity and violence , labute does manage to make a few points about modern man and his problematic quest for human connection .\n",
      "\n",
      "[ 0.46269107  0.53730893] home alone goes hollywood , a funny premise until the kids start pulling off stunts not even steven spielberg would know how to do . besides , real movie producers aren't this nice .\n",
      "\n",
      "[ 0.6032825  0.3967175] it has a subtle way of getting under your skin and sticking with you long after it's over .\n",
      "\n",
      "[ 0.03248133  0.96751867] nicolas philibert observes life inside a one-room schoolhouse in northern france in his documentary to be and to have , easily one of the best films of the year .\n",
      "\n",
      "[ 0.52089275  0.47910725] between bursts of automatic gunfire , the story offers a trenchant critique of capitalism .\n",
      "\n",
      "[ 0.49865798  0.50134202] it has the ability to offend and put off everyone , but it holds you with its outrageousness .\n",
      "\n",
      "[ 0.68342291  0.31657709] the streets , shot by cinematographer michael ballhaus , may be as authentic as they are mean , but it is nearly impossible to care about what happens on them .\n",
      "\n",
      "[ 0.20215378  0.79784622] it's difficult to conceive of anyone who has reached puberty actually finding the characters in slackers or their antics amusing , let alone funny .\n",
      "\n",
      "[ 0.93165166  0.06834834] traffics in the kind of prechewed racial clich�s that have already been through the corporate stand-up-comedy mill .\n",
      "\n",
      "[ 0.99887814  0.00112186] ultimately the , yes , snail-like pacing and lack of thematic resonance make the film more silly than scary , like some sort of martha stewart decorating program run amok .\n",
      "\n",
      "[ 0.93404742  0.06595258] plays like a checklist of everything rob reiner and his cast were sending up .\n",
      "\n",
      "[ 0.34983727  0.65016273] it certainly won't win any awards in the plot department but it sets out with no pretensions and delivers big time .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.882949\n",
      "Test Accuracy MULTINOMIAL: 0.705319\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.70      0.71      1803\n",
      "          -       0.70      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "[ 0.4849595  0.5150405] an edgy thriller that delivers a surprising punch .\n",
      "\n",
      "[ 0.53475197  0.46524803] a fiercely clever and subtle film , capturing the precarious balance between the extravagant confidence of the exiled aristocracy and the cruel earnestness of the victorious revolutionaries .\n",
      "\n",
      "[ 0.0311196  0.9688804] the film's strength isn't in its details , but in the larger picture it paints - of a culture in conflict with itself , with the thin veneer of nationalism that covers our deepest , media-soaked fears .\n",
      "\n",
      "[ 0.10967081  0.89032919] it's the chemistry between the women and the droll scene-stealing wit and wolfish pessimism of anna chancellor that makes this \" two weddings and a funeral \" fun .\n",
      "\n",
      "[ 0.05633176  0.94366824] exquisitely acted and masterfully if preciously interwoven� [the film] addresses in a fascinating , intelligent manner the intermingling of race , politics and local commerce .\n",
      "\n",
      "[ 0.54675458  0.45324542] soul is what's lacking in every character in this movie and , subsequently , the movie itself .\n",
      "\n",
      "[ 0.60407524  0.39592476] an odd , haphazard , and inconsequential romantic comedy .\n",
      "\n",
      "[ 0.27066196  0.72933804] while it may not add up to the sum of its parts , holofcener's film offers just enough insight to keep it from being simpleminded , and the ensemble cast is engaging enough to keep you from shifting in your chair too often .\n",
      "\n",
      "[ 0.71643666  0.28356334] a relatively effective little potboiler until its absurd , contrived , overblown , and entirely implausible finale .\n",
      "\n",
      "[ 0.8900205  0.1099795] for this sort of thing to work , we need agile performers , but the proficient , dull sorvino has no light touch , and rodan is out of his league .\n",
      "\n",
      "[ 0.72209025  0.27790975] a soggy , shapeless mess . . . just a dumb excuse for a waterlogged equivalent of a haunted-house movie .\n",
      "\n",
      "[ 0.92943299  0.07056701] by turns numbingly dull-witted and disquietingly creepy .\n",
      "\n",
      "[ 0.33770679  0.66229321] ub equally spoofs and celebrates the more outre aspects of 'black culture' and the dorkier aspects of 'white culture , ' even as it points out how inseparable the two are .\n",
      "\n",
      "[ 0.64243139  0.35756861] despite hoffman's best efforts , wilson remains a silent , lumpish cipher ; his encounters reveal nothing about who he is or who he was before .\n",
      "\n",
      "[ 0.81293303  0.18706697] while obviously an extremely personal work , it remains inextricably stuck in an emotionally unavailable rut .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tabla comparativa muestra las métricas obtenidas para cada caso al aplicar un clasificador Bayesiano Ingenuo Multinomial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Regresión Logı́stica Regularizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.734102\n",
      "Test Accuracy LOGISTIC: 0.671827\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.68      0.68      1803\n",
      "          -       0.67      0.66      0.67      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.879572\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.731495\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720799\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.723129\n",
      "Test Accuracy LOGISTIC: 0.654095\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.72      0.68      1803\n",
      "          -       0.67      0.58      0.62      1751\n",
      "\n",
      "avg / total       0.66      0.65      0.65      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.814856\n",
      "Test Accuracy LOGISTIC: 0.689840\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.977209\n",
      "Test Accuracy LOGISTIC: 0.668731\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.67      0.67      1803\n",
      "          -       0.66      0.67      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.991277\n",
      "Test Accuracy LOGISTIC: 0.656065\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.66      0.66      0.66      1803\n",
      "          -       0.65      0.65      0.65      1751\n",
      "\n",
      "avg / total       0.66      0.66      0.66      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.994373\n",
      "Test Accuracy LOGISTIC: 0.646777\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.65      0.65      1803\n",
      "          -       0.64      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Máquina de Vectores de Soporte (SVM) Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "\n",
    "#Lematizador\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lematizador sin stopwords\n",
    "texts_train_stopwords = [word_extractor2(text, stopWords = False) for text in train_df.Text]\n",
    "texts_test_stopwords = [word_extractor2(text, stopWords = False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stopwords)\n",
    "features_test = vectorizer.transform(texts_test_stopwords)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.808385\n",
      "Test Accuracy SVM: 0.688432\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.71      0.70      1803\n",
      "          -       0.69      0.67      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.921497\n",
      "Test Accuracy SVM: 0.698283\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.70      0.70      0.70      1803\n",
      "          -       0.69      0.70      0.69      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.991559\n",
      "Test Accuracy SVM: 0.650155\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.65      0.66      0.66      1803\n",
      "          -       0.65      0.64      0.64      1751\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.991840\n",
      "Test Accuracy SVM: 0.638334\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.65      0.64      1803\n",
      "          -       0.63      0.63      0.63      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.985650\n",
      "Test Accuracy SVM: 0.638615\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.66      0.65      1803\n",
      "          -       0.64      0.62      0.63      1751\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "texts_train_stemming = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test_stemming = [word_extractor(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train_stopwords))\n",
    "features_train = vectorizer.transform(texts_train_stemming)\n",
    "features_test = vectorizer.transform(texts_test_stemming)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### j) Comparando resultados métodos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
